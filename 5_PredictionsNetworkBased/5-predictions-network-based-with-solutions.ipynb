{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO-F-422 -  Statistical Foundations of Machine Learning \n",
    "\n",
    "### Jacopo De Stefani - __[Jacopo.De.Stefani@ulb.ac.be](mailto:Jacopo.De.Stefani@ulb.ac.be)__\n",
    "### Bertrand Lebichot - __[Bertrand.Lebichot@ulb.ac.be](mailto:Bertrand.Lebichot@ulb.ac.be)__\n",
    "### Arnaud Pollaris - __[Arnaud.Pollaris@ulb.ac.be](mailto:Arnaud.Pollaris@ulb.ac.be)__\n",
    "### Gianluca Bontempi - __[gbonte@ulb.ac.be](mailto:gbonte@ulb.ac.be)__\n",
    "\n",
    "## TP 5 - Predictions: Network-based methods\n",
    "\n",
    "####  April 23,2019 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal and dataset\n",
    "\n",
    "The goal is to review some ML concepts :\n",
    "\n",
    "* Neural Network\n",
    "* Cross-validation and bagging\n",
    "* Radial Basis Functions\n",
    "\n",
    "We will continue to work on the spam detection dataset (https://archive.ics.uci.edu/ml/datasets/spambase), using the package ``nutshell``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-23T14:46:51.768750Z",
     "start_time": "2019-04-23T14:46:49.653Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'nutshell' was built under R version 3.4.4\"Loading required package: nutshell.bbdb\n",
      "Warning message:\n",
      "\"package 'nutshell.bbdb' was built under R version 3.4.4\"Loading required package: nutshell.audioscrobbler\n",
      "Warning message:\n",
      "\"package 'nutshell.audioscrobbler' was built under R version 3.4.4\"Warning message:\n",
      "\"package 'devtools' was built under R version 3.4.2\"Warning message:\n",
      "\"package 'RSNNS' was built under R version 3.4.4\"Loading required package: Rcpp\n",
      "Warning message:\n",
      "\"package 'Rcpp' was built under R version 3.4.4\"SHA-1 hash of file is bf3c7b8ac910823b729e3ce73bb6ab5e6955ad3d\n"
     ]
    }
   ],
   "source": [
    "library(nutshell)\n",
    "library(nnet)\n",
    "library(devtools)\n",
    "library(RSNNS)\n",
    "data(spambase)\n",
    "source_url('https://gist.githubusercontent.com/Peque/41a9e20d6687f2f3108d/raw/85e14f3a292e126f1454864427e3a189c2fe33f3/nnet_plot_update.r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyFromConfusionMatrix <- function(confusion_matrix){\n",
    "    return((confusion_matrix[1,1]+confusion_matrix[2,2])/sum(confusion_matrix))\n",
    "}\n",
    "\n",
    "displayResults <- function(Y,Y_hat,explanatory_string=\"\"){\n",
    "    print(paste(\"[INFO] - Confusion matrix\",explanatory_string,\":\"))\n",
    "    confusion_matrix <- table(Y_hat,(Y == 1))\n",
    "    print(confusion_matrix)\n",
    "    accuracy <- accuracyFromConfusionMatrix(confusion_matrix)\n",
    "    misclassification_rate = 1 - accuracy\n",
    "    print(paste(\"[INFO] - Misclassification rate\",explanatory_string,\":\",misclassification_rate))\n",
    "    return(accuracy)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning and cognitive science, an artificial neural network (ANN) is a network \n",
    "of interconnected processing elements, called neurons, which are used to estimate or approximate functions that can depend on a large number of inputs that are generally unknown.\n",
    "The concept of artificial neural networks is inspired by the structure of the central nervous systems of animals, in particular the brain. \n",
    "In such biological neural networks, a set of units (i.e. the neurons) are interconnected with each other to form a data-processing network. The processing capability of the network depends on the strength of the connections between the neurons, which can be dynamically modified across time in response to external stimuli that the network is subject to.\n",
    "This dynamic adaptation of the connections gives this system the possibility to learn from the experiences it is subject to.\n",
    "\n",
    "Both artificial and neural networks are characterized by three features \\parencite{mackay2003information} : **architecture**, **activity** and **learning rules**:\n",
    "\n",
    "- The **architecture** is a specification of which input variables are involved in the network and what are the topological relationships between the nodes of the network.\n",
    "- The **activity rule** describes defines how the activities of the neurons change in response to each other (usually with a short time-scale dynamics).\n",
    "- The **learning rule** specifies the way in which the neural network's weights needs to be adapted with time. This learning is usually viewed as taking place on a longer time scale than the time scale of the dynamics under the activity rule. Usually the learning rule will depend on the activities of the neurons. It may also depend on the values of the target values supplied by a teacher.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our task, we will focus on a specific family of artificial neural networks, the multi-layer perceptron (MLP). \n",
    "The **architecture** of a multi-layer perceptron is organized in layers, with each layer being fully connected to the following. The first layer, also called input layer, is constituted by the input variables. Following it there are one or more intermediate layers, named hidden layers, yielding to an output layer with one output variable. In this type of network, information moves from the input nodes, through the hidden nodes, to the output node. Moreover, every connection between nodes has an associated weight.\n",
    "\n",
    "In the following, we will focus on a standard one-hidden layer network:\n",
    "![](ANN_FF.png)\n",
    "\n",
    "Described by the equation :\n",
    "\\begin{equation}\n",
    "m(\\mathbf{x}) = f_o \\left( b_o + \\sum_{j=1}^{|H|} w_{jo} \\cdot f_h \\left( \\sum_{k=1}^{|I|} w_{ik} x_{ik} + b_j  \\right) \\right)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "where $\\mathbf{x'}$ is the input vector $\\mathbf{x}$, augmented with 1, i.e., $\\mathbf{x'}= (1;\\mathbf{x}^T)^T$ , \n",
    "$w_{ij}$ is the weight of the connection between the $i^\\text{th}$ input node and the $j^\\text{th}$ hidden node, $w_{jo}$ are the weights of the connections between hidden node $j$ and the output node and $|H|$ is the number of hidden nodes. The number of hidden nodes ($|H|$) controls the complexity of the model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **activation rule** of such network is divided into two steps.\n",
    "Firstly, each node $j$ determines its activation $a_j$, by collecting the output of its input nodes:\n",
    "\\begin{equation}\n",
    "a_j = \\sum_{i} w_{ij} x_i \n",
    "\\end{equation}\n",
    "Then, the *activity* of the neuron is computed as a function of the value of the activation $a_j$. In the case of the considered network, we have two different activity functions: $f_h(\\cdot)$ for the hidden layer and $f_o(\\cdot)$ for the output node.\n",
    "Common choices for activity functions are:\n",
    "\n",
    "\\begin{align*}\n",
    "f(x) = x && \\text{Linear} \\\\\n",
    "f(x) = \\frac{1}{1+e^{-x}} && \\text{Logistic} \\\\\n",
    "f(x) = \\tanh(x) && \\text{Hyperbolic tangent} \\\\\n",
    "f(x) = \n",
    "\\begin{cases}\n",
    "1 & x > 0 \\\\\n",
    "-1 & x \\le 0 \\\\\n",
    "\\end{cases} && \\text{Threshold} \\\\\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concerning the **learning rule**, the weights are generally estimated using some specific\n",
    "optimization procedure, the most popular one being the backpropagation procedure \\parencite{rumelhart1988learning}. Usually, at the beginning, the weights are chosen to be random values near zero and the backpropagation procedure updates the weights in order to minimize the prediction errors. The backpropagation procedure could be done using all the available data in a single session (batch training) or providing the network one training example at a time (online training).\n",
    "The error function minimized by neural networks is nonconvex and so can have multiple local\n",
    "minima. In consequence, the final solution will depend on the value chosen as starting point.\n",
    "Because of this randomness, neural networks are often trained multiple times using different\n",
    "random starting values, and the outputs of the different networks are averaged to obtain the final predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "spambase_idx <- sample(1:nrow(spambase))\n",
    "half_split <- floor(nrow(spambase)/2)\n",
    "target_variable <- ncol(spambase)\n",
    "\n",
    "train_data <- spambase[spambase_idx[1:half_split],]\n",
    "test_data <- spambase[spambase_idx[(half_split+1):nrow(spambase)],]\n",
    "threshold <- 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca <- prcomp(spambase[, -target_variable],center=TRUE,scale.=TRUE,retx=TRUE)\n",
    "\n",
    "train_data_pca <- pca$x[spambase_idx[1:half_split],]\n",
    "test_data_pca <- pca$x[spambase_idx[(half_split+1):nrow(spambase)],]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>2300</li>\n",
       "\t<li>5</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 2300\n",
       "\\item 5\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 2300\n",
       "2. 5\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 2300    5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(train_data_pca[,1:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting with the implementation of the models, we will have a deeper look into the data. To be more precise, we will focus on the target variable ``ìs_spam``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'factor'"
      ],
      "text/latex": [
       "'factor'"
      ],
      "text/markdown": [
       "'factor'"
      ],
      "text/plain": [
       "[1] \"factor\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class(train_data[,target_variable])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the target variable is a categorical variable (i.e. a variable taking values from a fixed and limited set of values), neural networks cannot naturally deal with values that are not numeric.\n",
    "\n",
    "We than have two different possibilities to solve this issue:\n",
    "\n",
    "- **integer encoding** : Each category will be coded with an increasing integer number (e.g. 1,2,3,....)\n",
    "    - **Pro's** : Efficient encoding (especially with a large number of variables)\n",
    "    - **Con's** : Natural relation among coded values\n",
    "- **one-hot encoding** : Each category will be coded with an vector having a number of entries equal to the available categories\n",
    "    - **Pro's** : No relation among coded values\n",
    "    - **Con's** : Potentially high number of dummy output variables need to be added to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Integer encoding of is_spam:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>0</li>\n",
       "\t<li>0</li>\n",
       "\t<li>0</li>\n",
       "\t<li>1</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1\n",
       "2. 1\n",
       "3. 0\n",
       "4. 0\n",
       "5. 0\n",
       "6. 1\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1 1 0 0 0 1\n",
       "Levels: 0 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"One-hot encoding of is_spam:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>0</th><th scope=col>1</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0</td><td>1</td></tr>\n",
       "\t<tr><td>0</td><td>1</td></tr>\n",
       "\t<tr><td>1</td><td>0</td></tr>\n",
       "\t<tr><td>1</td><td>0</td></tr>\n",
       "\t<tr><td>1</td><td>0</td></tr>\n",
       "\t<tr><td>0</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       " 0 & 1\\\\\n",
       "\\hline\n",
       "\t 0 & 1\\\\\n",
       "\t 0 & 1\\\\\n",
       "\t 1 & 0\\\\\n",
       "\t 1 & 0\\\\\n",
       "\t 1 & 0\\\\\n",
       "\t 0 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "0 | 1 | \n",
       "|---|---|---|---|---|---|\n",
       "| 0 | 1 | \n",
       "| 0 | 1 | \n",
       "| 1 | 0 | \n",
       "| 1 | 0 | \n",
       "| 1 | 0 | \n",
       "| 0 | 1 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     0 1\n",
       "[1,] 0 1\n",
       "[2,] 0 1\n",
       "[3,] 1 0\n",
       "[4,] 1 0\n",
       "[5,] 1 0\n",
       "[6,] 0 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Integer encoding of is_spam:\")\n",
    "head(train_data[,target_variable])\n",
    "print(\"One-hot encoding of is_spam:\")\n",
    "head(class.ind(as.factor(train_data[,target_variable])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP - Single output network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by applying a multi layer perceptron to our problem.\n",
    "The input layer will be constituted by 57 neurons, one for each input variable in the Spambase dataset.\n",
    "The output layer will contain a single neuron, outputting the probability for the given input example, to be classified as spam.\n",
    "The hidden layer will be constituted by a given number (``hidden_neurons <- 5``) of hidden units.\n",
    "The objective of the **learning rule** here, is to tune the weights of the network in order to minimize the mean squared difference between the output of the network $\\hat{y}$ and the true values $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# weights:  296\n",
      "initial  value 1558.958360 \n",
      "iter  10 value 1357.424927\n",
      "iter  20 value 905.208838\n",
      "iter  30 value 722.924656\n",
      "iter  40 value 628.665519\n",
      "iter  50 value 443.148847\n",
      "iter  60 value 363.486830\n",
      "iter  70 value 306.564699\n",
      "iter  80 value 278.575777\n",
      "iter  90 value 244.017198\n",
      "iter 100 value 224.866944\n",
      "iter 110 value 202.516909\n",
      "iter 120 value 186.690561\n",
      "iter 130 value 178.093456\n",
      "iter 140 value 174.536682\n",
      "iter 150 value 172.726899\n",
      "iter 160 value 171.866747\n",
      "iter 170 value 170.608248\n",
      "iter 180 value 170.478232\n",
      "iter 190 value 170.474276\n",
      "iter 200 value 170.473952\n",
      "iter 200 value 170.473950\n",
      "final  value 170.473919 \n",
      "converged\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "a 57-5-1 network with 296 weights\n",
       "inputs: word_freq_make word_freq_address word_freq_all word_freq_3d word_freq_our word_freq_over word_freq_remove word_freq_internet word_freq_order word_freq_mail word_freq_receive word_freq_will word_freq_people word_freq_report word_freq_addresses word_freq_free word_freq_business word_freq_email word_freq_you word_freq_credit word_freq_your word_freq_font word_freq_000 word_freq_money word_freq_hp word_freq_hpl word_freq_george word_freq_650 word_freq_lab word_freq_labs word_freq_telnet word_freq_857 word_freq_data word_freq_415 word_freq_85 word_freq_technology word_freq_1999 word_freq_parts word_freq_pm word_freq_direct word_freq_cs word_freq_meeting word_freq_original word_freq_project word_freq_re word_freq_edu word_freq_table word_freq_conference char_freq_semicolon char_freq_left_paren char_freq_left_bracket char_freq_exclamation char_freq_dollar char_freq_pound capital_run_length_average capital_run_length_longest capital_run_length_total \n",
       "output(s): is_spam \n",
       "options were - entropy fitting "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>3807</th><td>2.016867e-05</td></tr>\n",
       "\t<tr><th scope=row>621</th><td>9.908771e-01</td></tr>\n",
       "\t<tr><th scope=row>1881</th><td>4.387432e-03</td></tr>\n",
       "\t<tr><th scope=row>1343</th><td>9.908771e-01</td></tr>\n",
       "\t<tr><th scope=row>3458</th><td>9.908771e-01</td></tr>\n",
       "\t<tr><th scope=row>3701</th><td>5.642029e-03</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|l}\n",
       "\t3807 & 2.016867e-05\\\\\n",
       "\t621 & 9.908771e-01\\\\\n",
       "\t1881 & 4.387432e-03\\\\\n",
       "\t1343 & 9.908771e-01\\\\\n",
       "\t3458 & 9.908771e-01\\\\\n",
       "\t3701 & 5.642029e-03\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 3807 | 2.016867e-05 | \n",
       "| 621 | 9.908771e-01 | \n",
       "| 1881 | 4.387432e-03 | \n",
       "| 1343 | 9.908771e-01 | \n",
       "| 3458 | 9.908771e-01 | \n",
       "| 3701 | 5.642029e-03 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]        \n",
       "3807 2.016867e-05\n",
       "621  9.908771e-01\n",
       "1881 4.387432e-03\n",
       "1343 9.908771e-01\n",
       "3458 9.908771e-01\n",
       "3701 5.642029e-03"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_nodes <- 5\n",
    "\n",
    "model_single_out <- nnet(is_spam ~ ., data=train_data,size=hidden_nodes,skip=FALSE,trace=T, maxit=3000,rang=0.2)\n",
    "model_single_out\n",
    "\n",
    "Y_pred<-predict(model_single_out,test_data[,-target_variable])\n",
    "Y_hat_single_out <- Y_pred > threshold \n",
    "\n",
    "head(Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then use a custom function (cf. https://beckmw.wordpress.com/2013/03/04/visualizing-neural-networks-from-the-nnet-package/) to visualize the fitted network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAhFBMVEUAAAAMDAwSEhIYGBgZ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\nBHXQ/wfe/mrHcItmtwAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot.nnet(model_single_out, alpha.val = 0.5, circle.col = list('lightgray', 'white'), bord.col = 'black', cex=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP - One hot encoding network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# weights:  302\n",
      "initial  value 1347.184241 \n",
      "iter  10 value 1012.498998\n",
      "iter  20 value 817.514392\n",
      "iter  30 value 460.009833\n",
      "iter  40 value 308.116019\n",
      "iter  50 value 238.722154\n",
      "iter  60 value 201.134558\n",
      "iter  70 value 184.313271\n",
      "iter  80 value 166.249169\n",
      "iter  90 value 160.722169\n",
      "iter 100 value 156.614153\n",
      "iter 110 value 154.129084\n",
      "iter 120 value 153.258905\n",
      "iter 130 value 153.027568\n",
      "iter 140 value 152.643174\n",
      "iter 150 value 152.463671\n",
      "iter 160 value 152.301060\n",
      "iter 170 value 152.143596\n",
      "iter 180 value 151.961107\n",
      "iter 190 value 151.841063\n",
      "iter 200 value 151.698976\n",
      "iter 210 value 151.487322\n",
      "iter 220 value 151.316655\n",
      "iter 230 value 151.165369\n",
      "iter 240 value 150.680352\n",
      "iter 250 value 149.935599\n",
      "iter 260 value 149.207127\n",
      "iter 270 value 149.090961\n",
      "iter 280 value 148.998750\n",
      "iter 290 value 148.943049\n",
      "iter 300 value 148.868398\n",
      "iter 310 value 148.739892\n",
      "iter 320 value 148.680460\n",
      "iter 330 value 148.647584\n",
      "iter 340 value 148.590201\n",
      "iter 350 value 148.543949\n",
      "iter 360 value 148.496356\n",
      "iter 370 value 148.463152\n",
      "iter 380 value 148.404928\n",
      "iter 390 value 148.373091\n",
      "iter 400 value 148.311992\n",
      "iter 410 value 148.274446\n",
      "iter 420 value 148.235351\n",
      "iter 430 value 148.217340\n",
      "iter 440 value 148.200180\n",
      "iter 450 value 148.184760\n",
      "iter 460 value 148.137857\n",
      "iter 470 value 148.110483\n",
      "iter 480 value 148.070313\n",
      "iter 490 value 148.044955\n",
      "iter 500 value 148.024378\n",
      "iter 510 value 148.004380\n",
      "iter 520 value 147.963876\n",
      "iter 530 value 147.922419\n",
      "iter 540 value 147.400130\n",
      "iter 550 value 146.727321\n",
      "iter 560 value 146.636069\n",
      "iter 570 value 146.557360\n",
      "iter 580 value 146.464340\n",
      "iter 590 value 146.364276\n",
      "iter 600 value 146.202850\n",
      "iter 610 value 145.896911\n",
      "iter 620 value 145.768508\n",
      "iter 630 value 145.489983\n",
      "iter 640 value 145.315750\n",
      "iter 650 value 145.282224\n",
      "iter 660 value 145.143903\n",
      "iter 670 value 145.046467\n",
      "iter 680 value 144.943696\n",
      "iter 690 value 144.914702\n",
      "iter 700 value 144.877494\n",
      "iter 710 value 144.830682\n",
      "iter 720 value 144.779628\n",
      "iter 730 value 144.738490\n",
      "iter 740 value 144.595570\n",
      "iter 750 value 144.561030\n",
      "iter 760 value 144.530359\n",
      "iter 770 value 144.497307\n",
      "iter 780 value 144.466363\n",
      "iter 790 value 144.436610\n",
      "iter 800 value 144.418122\n",
      "iter 810 value 144.397660\n",
      "iter 820 value 144.368553\n",
      "iter 830 value 144.350514\n",
      "iter 840 value 144.337082\n",
      "iter 850 value 144.329093\n",
      "iter 860 value 144.314978\n",
      "iter 870 value 144.300830\n",
      "iter 880 value 144.288687\n",
      "iter 890 value 144.266519\n",
      "iter 900 value 144.208357\n",
      "iter 910 value 144.179852\n",
      "iter 920 value 144.157144\n",
      "iter 930 value 144.136906\n",
      "iter 940 value 144.122294\n",
      "iter 950 value 144.109652\n",
      "iter 960 value 144.097860\n",
      "iter 970 value 144.085803\n",
      "iter 980 value 144.071515\n",
      "iter 990 value 144.060146\n",
      "iter1000 value 144.050139\n",
      "final  value 144.050139 \n",
      "stopped after 1000 iterations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "a 57-5-2 network with 302 weights\n",
       "options were -"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>0</th><th scope=col>1</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>3807</th><td>1.0000000  </td><td>0.000000000</td></tr>\n",
       "\t<tr><th scope=row>621</th><td>0.0000000  </td><td>1.000000000</td></tr>\n",
       "\t<tr><th scope=row>1881</th><td>1.0000000  </td><td>0.000000000</td></tr>\n",
       "\t<tr><th scope=row>1343</th><td>0.0000000  </td><td>1.000000000</td></tr>\n",
       "\t<tr><th scope=row>3458</th><td>0.9969206  </td><td>0.003081287</td></tr>\n",
       "\t<tr><th scope=row>3701</th><td>0.8071650  </td><td>0.192843254</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & 0 & 1\\\\\n",
       "\\hline\n",
       "\t3807 & 1.0000000   & 0.000000000\\\\\n",
       "\t621 & 0.0000000   & 1.000000000\\\\\n",
       "\t1881 & 1.0000000   & 0.000000000\\\\\n",
       "\t1343 & 0.0000000   & 1.000000000\\\\\n",
       "\t3458 & 0.9969206   & 0.003081287\\\\\n",
       "\t3701 & 0.8071650   & 0.192843254\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | 0 | 1 | \n",
       "|---|---|---|---|---|---|\n",
       "| 3807 | 1.0000000   | 0.000000000 | \n",
       "| 621 | 0.0000000   | 1.000000000 | \n",
       "| 1881 | 1.0000000   | 0.000000000 | \n",
       "| 1343 | 0.0000000   | 1.000000000 | \n",
       "| 3458 | 0.9969206   | 0.003081287 | \n",
       "| 3701 | 0.8071650   | 0.192843254 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     0         1          \n",
       "3807 1.0000000 0.000000000\n",
       "621  0.0000000 1.000000000\n",
       "1881 1.0000000 0.000000000\n",
       "1343 0.0000000 1.000000000\n",
       "3458 0.9969206 0.003081287\n",
       "3701 0.8071650 0.192843254"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_one_hot<-nnet(x=train_data[,-target_variable],\n",
    "               y=class.ind(as.factor(train_data[,target_variable])),\n",
    "               size=hidden_nodes,\n",
    "               skip=FALSE,\n",
    "               trace=T, \n",
    "               maxit=1000,\n",
    "               rang=0.5)\n",
    "\n",
    "model_one_hot\n",
    "\n",
    "Y_pred<-predict(model_one_hot,test_data[,-target_variable])\n",
    "Y_hat_one_hot <- Y_pred[,2] > threshold\n",
    "\n",
    "head(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAmVBMVEUAAAAGBgYMDAwNDQ0S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\nBHUQQIKgDgJIENRBAAmCOuj/AysSKWgMXVPOAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot.nnet(model_one_hot, alpha.val = 0.5, circle.col = list('lightgray', 'white'), bord.col = 'black', cex=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"[INFO] - Confusion matrix Single out :\"\n",
      "       \n",
      "Y_hat   FALSE TRUE\n",
      "  FALSE  1280   65\n",
      "  TRUE     95  861\n",
      "[1] \"[INFO] - Misclassification rate Single out : 0.069534984789222 \\n\"\n",
      "[1] \"[INFO] - Confusion matrix One hot :\"\n",
      "       \n",
      "Y_hat   FALSE TRUE\n",
      "  FALSE  1324  122\n",
      "  TRUE     51  804\n",
      "[1] \"[INFO] - Misclassification rate One hot : 0.0751847023033464 \\n\"\n"
     ]
    }
   ],
   "source": [
    "Y <- test_data[,target_variable]\n",
    "\n",
    "displayResults(Y,Y_hat_single_out,\"Single out\")\n",
    "displayResults(Y,Y_hat_one_hot,\"One hot\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "- Does the type of encoding affect the quality of the classifiers?\n",
    "- What does the $B_i$ nodes represent?\n",
    "- Does the number of hidden neurons affect the quality of the prediction?\n",
    "- If so, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-fold crossvalidation\n",
    "\n",
    "As the convergence of neural networks is highly influenced by the initial choice of weights, togheter with the choice of the optimization algorithm, it will be interesting to how the choice of these parameters will influence the performances of the model.  \n",
    "\n",
    "In order to do so, we ask you to implement $k$-fold cross validation and to compare:\n",
    "\n",
    "- In-sample error\n",
    "- Out-of-sample error\n",
    "- Crossvalidation error\n",
    "\n",
    "for a varying number of hidden nodes $\\in \\{3,5,10,15,20\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossValidationInOutSample <- function(hidden_nodes=5,k=10){\n",
    "    # 1. Shuffle the dataset randomly.\n",
    "    spambase_idx <- sample(1:nrow(spambase))\n",
    "\n",
    "    # 2. Split the dataset into k groups\n",
    "    max <- ceiling(nrow(spambase)/k)\n",
    "    splits <- split(spambase_idx, ceiling(seq_along(spambase_idx)/max))\n",
    "\n",
    "    # 3. For each unique group:\n",
    "    for (i in 1:k){\n",
    "        #3.1 Take the group as a hold out or test data set\n",
    "        train_data <- spambase[splits[[i]],]\n",
    "\n",
    "        #3.2 Take the remaining groups as a training data set\n",
    "        test_data <- spambase[-splits[[i]],]\n",
    "        print(paste(\"[INFO] - Training set size:\",dim(train_data)[1],\"- Testing set size\",dim(test_data)[1]))\n",
    "\n",
    "        #3.3 Fit a model on the training set and evaluate it on the test set\n",
    "        model_single_out <- nnet(is_spam ~ ., data=train_data,size=hidden_nodes,\n",
    "                                 skip=FALSE, maxit=3000,rang=0.2,MaxNWts=10000,trace=FALSE)\n",
    "\n",
    "        Y_pred<-predict(model_single_out,test_data[,-target_variable]) \n",
    "\n",
    "        Y <- test_data[,target_variable]\n",
    "\n",
    "        Y_hat <- Y_pred > threshold\n",
    "        confusion_matrix <- table(Y_hat,(Y == 1))\n",
    "\n",
    "        #3.4 Retain the evaluation score and discard the model\n",
    "        accuracy_vec[i] = (confusion_matrix[1,1]+confusion_matrix[2,2])/sum(confusion_matrix)\n",
    "        misclassification_rate = 1 - accuracy_vec[i]\n",
    "        print(paste(\"[INFO] - Misclassification rate -\",i,\"fold:\",misclassification_rate))\n",
    "    }\n",
    "\n",
    "    #4.1 Summarize the skill of the model using the sample of model evaluation scores\n",
    "    print(paste(\"[INFO] - CV - Mean misclassification rate:\",1-mean(accuracy_vec)))\n",
    "\n",
    "    Y <- test_data[,target_variable]\n",
    "\n",
    "    model_single_out <- nnet(is_spam ~ ., data=train_data,size=hidden_nodes,skip=FALSE, maxit=3000,rang=0.2,MaxNWts=10000)\n",
    "    model_single_out\n",
    "\n",
    "    # 4.2 - In sample evaluation error computation\n",
    "    Y_pred<-predict(model_single_out,train_data[,-target_variable])\n",
    "    Y_hat_single_out_in_sample <- Y_pred > threshold \n",
    "\n",
    "    # 4.2 - Out of sample evaluation error computation\n",
    "    Y_pred<-predict(model_single_out,test_data[,-target_variable])\n",
    "    Y_hat_single_out_out_sample <- Y_pred > threshold\n",
    "\n",
    "    accuracy_in_sample <- displayResults(train_data[,target_variable],Y_hat_single_out_in_sample,\"In sample\")\n",
    "    accuracy_out_sample <- displayResults(Y,Y_hat_single_out_out_sample,\"Out sample\")\n",
    "    \n",
    "    return(list(in_sample=accuracy_in_sample,out_sample=accuracy_out_sample,cv=mean(accuracy_vec)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"[INFO] - Training set size: 2301 - Testing set size 2300\"\n",
      "# weights:  178\n",
      "initial  value 1655.036931 \n",
      "iter  10 value 1383.389033\n",
      "iter  20 value 1230.524189\n",
      "iter  30 value 628.863967\n",
      "iter  40 value 414.424598\n",
      "iter  50 value 366.170883\n",
      "iter  60 value 319.741796\n",
      "iter  70 value 286.768407\n",
      "iter  80 value 274.923773\n",
      "iter  90 value 257.256649\n",
      "iter 100 value 244.605734\n",
      "iter 110 value 235.549518\n",
      "iter 120 value 231.006570\n",
      "iter 130 value 225.069636\n",
      "iter 140 value 223.201377\n",
      "iter 150 value 222.502208\n",
      "iter 160 value 222.051603\n",
      "iter 170 value 221.739371\n",
      "iter 180 value 221.399813\n",
      "iter 190 value 221.365209\n",
      "iter 200 value 221.344739\n",
      "iter 210 value 221.321905\n",
      "iter 220 value 221.300785\n",
      "iter 230 value 221.283144\n",
      "iter 240 value 221.260176\n",
      "iter 250 value 221.248476\n",
      "iter 260 value 221.241806\n",
      "iter 270 value 221.239025\n",
      "iter 280 value 221.236562\n",
      "iter 290 value 221.235399\n",
      "iter 300 value 221.229161\n",
      "iter 310 value 221.222113\n",
      "iter 320 value 221.220115\n",
      "final  value 221.219221 \n",
      "converged\n",
      "[1] \"[INFO] - Misclassification rate - 1 fold: 0.0695652173913044\"\n",
      "[1] \"[INFO] - Training set size: 2300 - Testing set size 2301\"\n",
      "# weights:  178\n",
      "initial  value 1570.842680 \n",
      "iter  10 value 1477.841660\n",
      "iter  20 value 838.993109\n",
      "iter  30 value 504.799451\n",
      "iter  40 value 430.554618\n",
      "iter  50 value 399.272344\n",
      "iter  60 value 376.711249\n",
      "iter  70 value 330.769392\n",
      "iter  80 value 315.196752\n",
      "iter  90 value 300.482330\n",
      "iter 100 value 289.669519\n",
      "iter 110 value 278.138601\n",
      "iter 120 value 271.981410\n",
      "iter 130 value 264.518988\n",
      "iter 140 value 255.349468\n",
      "iter 150 value 254.407976\n",
      "iter 160 value 254.279311\n",
      "iter 170 value 254.275968\n",
      "final  value 254.275928 \n",
      "converged\n",
      "[1] \"[INFO] - Misclassification rate - 2 fold: 0.0647544545849631\"\n",
      "[1] \"[INFO] - CV - Mean misclassification rate: 0.100319378517274\"\n",
      "# weights:  178\n",
      "initial  value 1551.191658 \n",
      "iter  10 value 1406.708061\n",
      "iter  20 value 752.270657\n",
      "iter  30 value 444.476061\n",
      "iter  40 value 394.384549\n",
      "iter  50 value 368.068578\n",
      "iter  60 value 350.149036\n",
      "iter  70 value 344.242876\n",
      "iter  80 value 336.593749\n",
      "iter  90 value 323.986246\n",
      "iter 100 value 314.898776\n",
      "iter 110 value 303.837534\n",
      "iter 120 value 285.176139\n",
      "iter 130 value 279.100624\n",
      "iter 140 value 276.901760\n",
      "iter 150 value 275.133141\n",
      "iter 160 value 273.522325\n",
      "iter 170 value 272.723571\n",
      "iter 180 value 271.987756\n",
      "iter 190 value 270.618876\n",
      "iter 200 value 269.388434\n",
      "iter 210 value 266.866388\n",
      "iter 220 value 265.072417\n",
      "final  value 264.233639 \n",
      "converged\n",
      "[1] \"[INFO] - Confusion matrix In sample :\"\n",
      "       \n",
      "Y_hat   FALSE TRUE\n",
      "  FALSE  1368   44\n",
      "  TRUE     27  861\n",
      "[1] \"[INFO] - Misclassification rate In sample : 0.0308695652173913\"\n",
      "[1] \"[INFO] - Confusion matrix Out sample :\"\n",
      "       \n",
      "Y_hat   FALSE TRUE\n",
      "  FALSE  1337   74\n",
      "  TRUE     56  834\n",
      "[1] \"[INFO] - Misclassification rate Out sample : 0.056497175141243\"\n",
      "[1] \"[INFO] - Training set size: 2301 - Testing set size 2300\"\n",
      "# weights:  296\n",
      "initial  value 1573.004591 \n",
      "iter  10 value 1487.690610\n",
      "iter  20 value 718.174369\n",
      "iter  30 value 478.172540\n",
      "iter  40 value 392.398528\n",
      "iter  50 value 354.104788\n",
      "iter  60 value 343.664693\n",
      "iter  70 value 331.930721\n",
      "iter  80 value 323.286832\n",
      "iter  90 value 314.721605\n",
      "iter 100 value 309.691759\n",
      "iter 110 value 298.661091\n",
      "iter 120 value 291.840268\n",
      "iter 130 value 286.107873\n",
      "iter 140 value 274.800619\n",
      "iter 150 value 260.428096\n",
      "iter 160 value 255.046428\n",
      "iter 170 value 246.672054\n",
      "iter 180 value 240.020400\n",
      "iter 190 value 236.465661\n",
      "iter 200 value 233.666720\n",
      "iter 210 value 231.579868\n",
      "iter 220 value 230.812090\n",
      "iter 230 value 230.207463\n",
      "iter 240 value 230.054122\n",
      "iter 250 value 228.911046\n",
      "iter 260 value 228.048439\n",
      "iter 270 value 225.477665\n",
      "iter 280 value 224.952936\n",
      "iter 290 value 224.587210\n",
      "iter 300 value 224.001039\n",
      "iter 310 value 222.415892\n",
      "iter 320 value 220.199301\n",
      "iter 330 value 219.274760\n",
      "iter 340 value 218.542180\n",
      "iter 350 value 216.837684\n",
      "iter 360 value 215.569314\n",
      "iter 370 value 214.667735\n",
      "iter 380 value 214.360436\n",
      "iter 390 value 213.979694\n",
      "iter 400 value 213.750750\n",
      "iter 410 value 213.552936\n",
      "iter 420 value 213.245145\n",
      "iter 430 value 213.035001\n",
      "iter 440 value 212.807329\n",
      "iter 450 value 211.957713\n",
      "iter 460 value 211.463596\n",
      "iter 470 value 211.275327\n",
      "iter 480 value 211.121793\n",
      "iter 490 value 210.806596\n",
      "iter 500 value 210.666298\n",
      "iter 510 value 210.485630\n",
      "iter 520 value 210.167918\n",
      "iter 530 value 209.856037\n",
      "iter 540 value 209.605952\n",
      "iter 550 value 209.411122\n",
      "iter 560 value 209.267717\n",
      "iter 570 value 208.950823\n",
      "iter 580 value 208.660778\n",
      "iter 590 value 208.637314\n",
      "iter 600 value 208.588621\n",
      "iter 610 value 208.554317\n",
      "iter 620 value 208.497931\n",
      "iter 630 value 208.443287\n",
      "iter 640 value 208.392538\n",
      "iter 650 value 208.358657\n",
      "iter 660 value 208.323840\n",
      "iter 670 value 208.305187\n",
      "iter 680 value 208.289636\n",
      "iter 690 value 208.277019\n",
      "iter 700 value 208.258259\n",
      "final  value 208.239020 \n",
      "converged\n",
      "[1] \"[INFO] - Misclassification rate - 1 fold: 0.077391304347826\"\n",
      "[1] \"[INFO] - Training set size: 2300 - Testing set size 2301\"\n",
      "# weights:  296\n",
      "initial  value 1594.582714 \n",
      "iter  10 value 1448.318417\n",
      "iter  20 value 878.864689\n",
      "iter  30 value 793.697925\n",
      "iter  40 value 508.747196\n",
      "iter  50 value 385.592571\n",
      "iter  60 value 313.141393\n",
      "iter  70 value 281.267162\n",
      "iter  80 value 260.465847\n",
      "iter  90 value 240.561816\n",
      "iter 100 value 227.147172\n",
      "iter 110 value 220.074972\n",
      "iter 120 value 209.810991\n",
      "iter 130 value 200.457619\n",
      "iter 140 value 194.419665\n",
      "iter 150 value 189.218686\n",
      "iter 160 value 188.111531\n",
      "iter 170 value 187.874954\n",
      "iter 180 value 187.609967\n",
      "iter 190 value 187.591207\n",
      "iter 200 value 187.590420\n",
      "final  value 187.590292 \n",
      "converged\n",
      "[1] \"[INFO] - Misclassification rate - 2 fold: 0.0856149500217297\"\n",
      "[1] \"[INFO] - CV - Mean misclassification rate: 0.103188036756603\"\n",
      "# weights:  296\n",
      "initial  value 1555.928546 \n",
      "iter  10 value 1417.912287\n",
      "iter  20 value 1005.757122\n",
      "iter  30 value 755.604202\n",
      "iter  40 value 575.262643\n",
      "iter  50 value 404.575424\n",
      "iter  60 value 355.648309\n",
      "iter  70 value 341.535881\n",
      "iter  80 value 333.696980\n",
      "iter  90 value 318.930043\n",
      "iter 100 value 306.209151\n",
      "iter 110 value 288.983357\n",
      "iter 120 value 266.733327\n",
      "iter 130 value 254.968699\n",
      "iter 140 value 248.626407\n",
      "iter 150 value 241.168257\n",
      "iter 160 value 236.208721\n",
      "iter 170 value 232.444091\n",
      "iter 180 value 231.242271\n",
      "iter 190 value 229.397728\n",
      "iter 200 value 228.028875\n",
      "iter 210 value 227.755339\n",
      "iter 220 value 227.438468\n",
      "iter 230 value 227.024344\n",
      "iter 240 value 226.635260\n",
      "iter 250 value 226.405481\n",
      "iter 260 value 226.346741\n",
      "iter 270 value 226.139191\n",
      "iter 280 value 226.017244\n",
      "iter 290 value 225.928431\n",
      "iter 300 value 225.868771\n",
      "iter 310 value 225.725203\n",
      "iter 320 value 225.674192\n",
      "iter 330 value 225.604184\n",
      "iter 340 value 224.603208\n",
      "iter 350 value 224.493367\n",
      "iter 360 value 224.230542\n",
      "iter 370 value 223.992770\n",
      "iter 380 value 223.894005\n",
      "iter 390 value 223.846202\n",
      "iter 400 value 223.780537\n",
      "iter 410 value 223.754807\n",
      "iter 420 value 223.731422\n",
      "iter 430 value 223.691640\n",
      "iter 440 value 223.616190\n",
      "iter 450 value 223.580177\n",
      "iter 460 value 223.553090\n",
      "iter 470 value 223.526719\n",
      "iter 480 value 223.505927\n",
      "iter 490 value 223.482663\n",
      "iter 500 value 223.451006\n",
      "iter 510 value 223.430006\n",
      "iter 520 value 223.421381\n",
      "iter 530 value 223.403528\n",
      "iter 540 value 223.390379\n",
      "iter 550 value 223.385230\n",
      "final  value 223.376284 \n",
      "converged\n",
      "[1] \"[INFO] - Confusion matrix In sample :\"\n",
      "       \n",
      "Y_hat   FALSE TRUE\n",
      "  FALSE  1352   35\n",
      "  TRUE     38  875\n",
      "[1] \"[INFO] - Misclassification rate In sample : 0.0317391304347826\"\n",
      "[1] \"[INFO] - Confusion matrix Out sample :\"\n",
      "       \n",
      "Y_hat   FALSE TRUE\n",
      "  FALSE  1326   89\n",
      "  TRUE     72  814\n",
      "[1] \"[INFO] - Misclassification rate Out sample : 0.0699695784441547\"\n",
      "[1] \"[INFO] - Training set size: 2301 - Testing set size 2300\"\n",
      "# weights:  591\n",
      "initial  value 1588.366979 \n",
      "iter  10 value 1320.873081\n",
      "iter  20 value 1002.849355\n",
      "iter  30 value 887.412038\n",
      "iter  40 value 560.144864\n",
      "iter  50 value 454.955775\n",
      "iter  60 value 371.037573\n",
      "iter  70 value 318.827412\n",
      "iter  80 value 265.358850\n",
      "iter  90 value 239.892563\n",
      "iter 100 value 222.243882\n",
      "iter 110 value 210.819697\n",
      "iter 120 value 205.388984\n",
      "iter 130 value 203.811221\n",
      "iter 140 value 200.416771\n",
      "iter 150 value 197.817180\n",
      "iter 160 value 193.771516\n",
      "iter 170 value 191.082879\n",
      "iter 180 value 188.215783\n",
      "iter 190 value 187.055568\n",
      "iter 200 value 186.328132\n",
      "iter 210 value 186.002724\n",
      "iter 220 value 184.594102\n",
      "iter 230 value 180.622924\n",
      "iter 240 value 176.284809\n",
      "iter 250 value 173.114558\n",
      "iter 260 value 167.391717\n",
      "iter 270 value 163.508021\n",
      "iter 280 value 160.182985\n",
      "iter 290 value 158.345160\n",
      "iter 300 value 156.339085\n",
      "iter 310 value 156.066360\n",
      "iter 320 value 155.535215\n",
      "iter 330 value 155.181246\n",
      "iter 340 value 154.715191\n",
      "iter 350 value 154.238626\n",
      "iter 360 value 153.973480\n",
      "iter 370 value 153.686346\n",
      "iter 380 value 153.446456\n",
      "iter 390 value 153.238513\n",
      "iter 400 value 152.840183\n",
      "iter 410 value 152.694424\n",
      "iter 420 value 152.326362\n",
      "iter 430 value 151.993428\n",
      "iter 440 value 151.584940\n",
      "iter 450 value 151.426236\n",
      "iter 460 value 150.944316\n",
      "iter 470 value 150.795656\n",
      "iter 480 value 150.746082\n",
      "iter 490 value 150.616090\n",
      "iter 500 value 150.383808\n",
      "iter 510 value 149.958627\n",
      "iter 520 value 149.625262\n",
      "iter 530 value 149.124413\n",
      "iter 540 value 148.550188\n",
      "iter 550 value 148.155625\n",
      "iter 560 value 147.754362\n",
      "iter 570 value 146.438643\n",
      "iter 580 value 146.087079\n",
      "iter 590 value 145.025687\n",
      "iter 600 value 143.666149\n",
      "iter 610 value 143.117009\n",
      "iter 620 value 142.865837\n",
      "iter 630 value 141.713624\n",
      "iter 640 value 140.312189\n",
      "iter 650 value 140.135478\n",
      "iter 660 value 139.907162\n",
      "iter 670 value 139.373708\n",
      "iter 680 value 139.250103\n",
      "iter 690 value 139.140550\n",
      "iter 700 value 138.912457\n",
      "iter 710 value 138.690697\n",
      "iter 720 value 138.551885\n",
      "iter 730 value 138.382662\n",
      "iter 740 value 138.263675\n",
      "iter 750 value 137.653492\n",
      "iter 760 value 136.742051\n",
      "iter 770 value 135.960632\n",
      "iter 780 value 135.880564\n",
      "iter 790 value 135.766511\n",
      "iter 800 value 135.591640\n",
      "iter 810 value 135.491207\n",
      "iter 820 value 135.457845\n",
      "iter 830 value 135.451387\n",
      "iter 840 value 135.412455\n",
      "iter 850 value 135.381003\n",
      "iter 860 value 135.373760\n",
      "iter 870 value 135.363648\n",
      "iter 880 value 135.353392\n",
      "iter 890 value 135.350511\n",
      "iter 900 value 135.338866\n",
      "iter 910 value 135.324016\n",
      "iter 920 value 135.303267\n",
      "iter 930 value 135.284080\n",
      "iter 940 value 135.275267\n",
      "iter 950 value 135.266867\n",
      "final  value 135.263530 \n",
      "converged\n",
      "[1] \"[INFO] - Misclassification rate - 1 fold: 0.0852173913043478\"\n",
      "[1] \"[INFO] - Training set size: 2300 - Testing set size 2301\"\n",
      "# weights:  591\n",
      "initial  value 1571.832613 \n",
      "iter  10 value 1455.137682\n",
      "iter  20 value 1376.099875\n",
      "iter  30 value 830.332833\n",
      "iter  40 value 502.150010\n",
      "iter  50 value 394.924930\n",
      "iter  60 value 310.080606\n",
      "iter  70 value 269.122182\n",
      "iter  80 value 238.504164\n",
      "iter  90 value 207.709631\n",
      "iter 100 value 189.170608\n",
      "iter 110 value 176.876615\n",
      "iter 120 value 168.826453\n",
      "iter 130 value 161.079909\n",
      "iter 140 value 153.043134\n",
      "iter 150 value 150.524180\n",
      "iter 160 value 147.733021\n",
      "iter 170 value 141.831465\n",
      "iter 180 value 139.796703\n",
      "iter 190 value 137.386936\n",
      "iter 200 value 135.454860\n",
      "iter 210 value 133.521706\n",
      "iter 220 value 131.447111\n",
      "iter 230 value 129.403124\n",
      "iter 240 value 128.752627\n",
      "iter 250 value 128.165208\n",
      "iter 260 value 127.625044\n",
      "iter 270 value 127.246209\n",
      "iter 280 value 126.722699\n",
      "iter 290 value 126.282276\n",
      "iter 300 value 125.778972\n",
      "iter 310 value 125.208875\n",
      "iter 320 value 124.466541\n",
      "iter 330 value 123.961375\n",
      "iter 340 value 123.378551\n",
      "iter 350 value 122.599858\n",
      "iter 360 value 121.749564\n",
      "iter 370 value 120.874520\n",
      "iter 380 value 120.133662\n",
      "iter 390 value 119.220583\n",
      "iter 400 value 118.452714\n",
      "iter 410 value 117.807803\n",
      "iter 420 value 117.352519\n",
      "iter 430 value 116.448731\n",
      "iter 440 value 116.080844\n",
      "iter 450 value 115.814921\n",
      "iter 460 value 115.610435\n",
      "iter 470 value 115.356140\n",
      "iter 480 value 115.106006\n",
      "iter 490 value 114.923738\n",
      "iter 500 value 114.705466\n",
      "iter 510 value 114.229805\n",
      "iter 520 value 113.991374\n",
      "iter 530 value 113.819869\n",
      "iter 540 value 113.708506\n",
      "iter 550 value 113.637643\n",
      "iter 560 value 113.555063\n",
      "iter 570 value 113.507047\n",
      "iter 580 value 113.465669\n",
      "iter 590 value 113.433835\n",
      "iter 600 value 113.402852\n",
      "iter 610 value 113.371381\n",
      "iter 620 value 113.344561\n",
      "iter 630 value 113.332114\n",
      "iter 640 value 113.326247\n",
      "iter 650 value 113.317604\n",
      "iter 660 value 113.309585\n",
      "iter 670 value 113.300189\n",
      "iter 680 value 113.293849\n",
      "iter 690 value 113.283932\n",
      "iter 700 value 113.270296\n",
      "iter 710 value 113.252771\n",
      "iter 720 value 113.209023\n",
      "iter 730 value 113.178606\n",
      "iter 740 value 113.166625\n",
      "iter 750 value 113.114603\n",
      "iter 760 value 113.103268\n",
      "iter 770 value 113.093079\n",
      "iter 780 value 113.088135\n",
      "iter 790 value 113.083033\n",
      "iter 800 value 113.076836\n",
      "iter 810 value 113.070294\n",
      "iter 820 value 113.061551\n",
      "iter 830 value 113.050782\n",
      "iter 840 value 113.043277\n",
      "iter 850 value 113.032556\n",
      "iter 860 value 112.697772\n",
      "iter 870 value 112.679765\n",
      "iter 880 value 112.670265\n",
      "iter 890 value 112.643552\n",
      "iter 900 value 112.633450\n",
      "iter 910 value 112.625438\n",
      "iter 920 value 112.620512\n",
      "iter 930 value 112.616463\n",
      "iter 940 value 112.612538\n",
      "iter 950 value 112.609684\n",
      "iter 960 value 112.608337\n",
      "iter 970 value 112.604732\n",
      "iter 980 value 112.602529\n",
      "iter 990 value 112.598560\n",
      "iter1000 value 112.596900\n",
      "iter1010 value 112.593524\n",
      "iter1020 value 112.589622\n",
      "iter1030 value 112.584971\n",
      "iter1040 value 112.576135\n",
      "iter1050 value 112.564224\n",
      "final  value 112.555636 \n",
      "converged\n",
      "[1] \"[INFO] - Misclassification rate - 2 fold: 0.0764884832681443\"\n",
      "[1] \"[INFO] - CV - Mean misclassification rate: 0.103057998776897\"\n",
      "# weights:  591\n",
      "initial  value 1709.300585 \n",
      "iter  10 value 1464.582868\n",
      "iter  20 value 1232.594718\n",
      "iter  30 value 1166.574929\n",
      "iter  40 value 704.190598\n",
      "iter  50 value 646.030533\n",
      "iter  60 value 370.022944\n",
      "iter  70 value 268.779673\n",
      "iter  80 value 231.308078\n",
      "iter  90 value 202.563644\n",
      "iter 100 value 179.174129\n",
      "iter 110 value 168.565094\n",
      "iter 120 value 158.016137\n",
      "iter 130 value 153.083767\n",
      "iter 140 value 147.615894\n",
      "iter 150 value 141.952530\n",
      "iter 160 value 138.642968\n",
      "iter 170 value 135.408595\n",
      "iter 180 value 132.277252\n",
      "iter 190 value 130.992768\n",
      "iter 200 value 130.546132\n",
      "iter 210 value 130.097821\n",
      "iter 220 value 129.866620\n",
      "iter 230 value 129.455465\n",
      "iter 240 value 129.168529\n",
      "final  value 129.120938 \n",
      "converged\n",
      "[1] \"[INFO] - Confusion matrix In sample :\"\n",
      "       \n",
      "Y_hat   FALSE TRUE\n",
      "  FALSE  1362    4\n",
      "  TRUE     31  903\n",
      "[1] \"[INFO] - Misclassification rate In sample : 0.0152173913043478\"\n",
      "[1] \"[INFO] - Confusion matrix Out sample :\"\n",
      "       \n",
      "Y_hat   FALSE TRUE\n",
      "  FALSE  1305   84\n",
      "  TRUE     90  822\n",
      "[1] \"[INFO] - Misclassification rate Out sample : 0.075619295958279\"\n",
      "[1] \"[INFO] - Training set size: 2301 - Testing set size 2300\"\n",
      "# weights:  886\n",
      "initial  value 1598.269569 \n",
      "iter  10 value 1387.311061\n",
      "iter  20 value 1283.154849\n",
      "iter  30 value 824.343465\n",
      "iter  40 value 527.398509\n",
      "iter  50 value 409.757809\n",
      "iter  60 value 329.182517\n",
      "iter  70 value 316.226847\n",
      "iter  80 value 299.289406\n",
      "iter  90 value 269.174504\n",
      "iter 100 value 246.688633\n",
      "iter 110 value 244.984744\n",
      "iter 120 value 235.158349\n",
      "iter 130 value 205.251648\n",
      "iter 140 value 183.337350\n",
      "iter 150 value 168.043831\n",
      "iter 160 value 152.751524\n",
      "iter 170 value 137.740462\n",
      "iter 180 value 131.974236\n",
      "iter 190 value 130.710094\n",
      "iter 200 value 129.357305\n",
      "iter 210 value 126.916258\n",
      "iter 220 value 123.904848\n",
      "iter 230 value 122.857570\n",
      "iter 240 value 120.737532\n",
      "iter 250 value 118.692252\n",
      "iter 260 value 115.663549\n",
      "iter 270 value 108.841630\n",
      "iter 280 value 105.894733\n",
      "iter 290 value 103.009984\n",
      "iter 300 value 99.969583\n",
      "iter 310 value 96.910317\n",
      "iter 320 value 92.833871\n",
      "iter 330 value 89.700777\n",
      "iter 340 value 84.664096\n",
      "iter 350 value 80.358888\n",
      "iter 360 value 78.538858\n",
      "iter 370 value 78.024530\n",
      "iter 380 value 77.930658\n",
      "iter 390 value 77.852788\n",
      "iter 400 value 77.809463\n",
      "iter 410 value 77.716731\n",
      "iter 420 value 77.683526\n",
      "iter 430 value 77.606904\n",
      "iter 440 value 77.545542\n",
      "iter 450 value 77.532347\n",
      "iter 460 value 77.526618\n",
      "iter 470 value 77.520074\n",
      "iter 480 value 77.516883\n",
      "iter 490 value 77.514880\n",
      "iter 500 value 77.513126\n",
      "iter 510 value 77.511678\n",
      "iter 520 value 77.509623\n",
      "iter 530 value 77.507938\n",
      "iter 540 value 77.507192\n",
      "iter 550 value 77.506138\n",
      "iter 560 value 77.504426\n",
      "iter 570 value 77.503237\n",
      "iter 580 value 77.502159\n",
      "iter 590 value 77.501417\n",
      "iter 600 value 77.500330\n",
      "iter 610 value 77.499451\n",
      "iter 620 value 77.498596\n",
      "iter 630 value 77.497399\n",
      "iter 640 value 77.496696\n",
      "iter 650 value 77.495950\n",
      "iter 660 value 77.494948\n",
      "iter 670 value 77.494005\n",
      "iter 680 value 76.772705\n",
      "iter 690 value 76.141305\n",
      "iter 700 value 71.991307\n",
      "iter 710 value 67.713143\n",
      "iter 720 value 67.382956\n",
      "iter 730 value 67.257214\n",
      "iter 740 value 66.663034\n",
      "iter 750 value 65.474161\n",
      "iter 760 value 65.141837\n",
      "iter 770 value 65.038997\n",
      "iter 780 value 64.828551\n",
      "iter 790 value 64.279075\n",
      "iter 800 value 62.281528\n",
      "iter 810 value 61.851976\n",
      "iter 820 value 61.792586\n",
      "iter 830 value 61.739040\n",
      "iter 840 value 61.707981\n",
      "iter 850 value 61.678139\n",
      "iter 860 value 61.669640\n",
      "iter 870 value 61.658345\n",
      "iter 880 value 61.646013\n",
      "iter 890 value 61.633049\n",
      "iter 900 value 61.621377\n",
      "iter 910 value 61.605218\n",
      "iter 920 value 61.597033\n",
      "iter 930 value 60.544251\n",
      "iter 940 value 58.780246\n",
      "iter 950 value 58.661167\n",
      "iter 960 value 58.651384\n",
      "iter 970 value 58.641118\n",
      "iter 980 value 58.636672\n",
      "iter 990 value 58.630456\n",
      "iter1000 value 58.629117\n",
      "iter1010 value 58.627380\n",
      "iter1020 value 58.626574\n",
      "iter1030 value 58.542236\n",
      "iter1040 value 58.539341\n",
      "iter1050 value 58.533736\n",
      "iter1060 value 58.528818\n",
      "iter1070 value 58.522982\n",
      "iter1080 value 58.519889\n",
      "iter1090 value 58.516288\n",
      "iter1090 value 58.516288\n",
      "iter1100 value 58.513602\n",
      "iter1110 value 58.512116\n",
      "iter1120 value 58.508692\n",
      "iter1130 value 58.508042\n",
      "iter1140 value 58.507742\n",
      "iter1150 value 58.507332\n",
      "iter1160 value 58.506202\n",
      "iter1170 value 58.500408\n",
      "iter1180 value 58.475684\n",
      "iter1190 value 58.471752\n",
      "iter1200 value 58.469812\n",
      "iter1210 value 58.469135\n",
      "iter1220 value 58.468573\n",
      "iter1230 value 58.467960\n",
      "iter1240 value 58.467552\n",
      "iter1250 value 58.467236\n",
      "iter1260 value 58.466776\n",
      "iter1270 value 58.466328\n",
      "iter1280 value 58.442660\n",
      "iter1290 value 58.437061\n",
      "iter1300 value 58.435832\n",
      "iter1310 value 58.434730\n",
      "iter1320 value 58.434102\n",
      "iter1330 value 58.433684\n",
      "iter1340 value 58.433095\n",
      "iter1350 value 58.431977\n",
      "iter1360 value 58.425923\n",
      "iter1370 value 58.419569\n",
      "iter1380 value 58.417634\n",
      "iter1390 value 58.411984\n",
      "iter1400 value 58.407316\n",
      "iter1410 value 58.377947\n",
      "iter1420 value 58.263099\n",
      "iter1430 value 58.250443\n",
      "iter1440 value 58.243699\n",
      "iter1450 value 58.241481\n",
      "iter1460 value 58.230141\n",
      "iter1470 value 58.203048\n",
      "iter1480 value 58.200079\n",
      "iter1490 value 58.196281\n",
      "iter1500 value 58.193450\n",
      "iter1510 value 58.188423\n",
      "iter1520 value 58.182614\n",
      "iter1530 value 58.175678\n",
      "iter1540 value 58.167108\n",
      "iter1550 value 58.151559\n",
      "iter1560 value 58.127563\n",
      "iter1570 value 58.119205\n",
      "iter1580 value 58.106998\n",
      "iter1590 value 58.101499\n",
      "iter1600 value 58.090478\n",
      "iter1610 value 58.072014\n",
      "iter1620 value 58.044189\n",
      "iter1630 value 58.027193\n",
      "iter1640 value 58.014597\n",
      "iter1650 value 57.993005\n",
      "iter1660 value 57.982014\n",
      "iter1670 value 57.980586\n",
      "iter1680 value 57.973548\n",
      "iter1690 value 57.958528\n",
      "iter1700 value 57.950933\n",
      "iter1710 value 57.947945\n",
      "iter1720 value 57.941410\n",
      "iter1730 value 57.939190\n",
      "iter1740 value 57.938215\n",
      "iter1750 value 57.937842\n",
      "iter1760 value 57.936857\n",
      "iter1770 value 57.935795\n",
      "iter1780 value 57.935067\n",
      "iter1790 value 57.933724\n",
      "iter1800 value 57.932568\n",
      "iter1810 value 57.930019\n",
      "iter1820 value 57.928725\n",
      "iter1830 value 57.927364\n",
      "iter1840 value 57.926911\n",
      "iter1850 value 57.926635\n",
      "iter1860 value 57.926006\n",
      "iter1870 value 57.916401\n",
      "iter1880 value 57.903560\n",
      "iter1890 value 57.901414\n",
      "iter1900 value 57.898563\n",
      "iter1910 value 57.892097\n",
      "iter1920 value 57.861011\n",
      "iter1930 value 57.848640\n",
      "iter1940 value 57.839604\n",
      "iter1950 value 57.829344\n",
      "iter1960 value 57.806894\n",
      "iter1970 value 57.787929\n",
      "iter1980 value 57.770710\n",
      "iter1990 value 57.756489\n",
      "iter2000 value 57.749788\n",
      "iter2010 value 57.742139\n",
      "iter2020 value 57.731681\n",
      "iter2030 value 57.722123\n",
      "iter2040 value 57.689386\n",
      "iter2050 value 57.668298\n",
      "iter2060 value 57.649825\n",
      "iter2070 value 57.623771\n",
      "iter2080 value 57.592743\n",
      "iter2090 value 57.579885\n",
      "iter2100 value 57.561248\n",
      "iter2110 value 57.530421\n",
      "iter2120 value 57.521346\n",
      "iter2130 value 57.507181\n",
      "iter2140 value 57.496672\n",
      "iter2150 value 57.486979\n",
      "iter2160 value 57.478320\n",
      "iter2170 value 57.471630\n",
      "iter2180 value 57.461647\n",
      "iter2190 value 57.453164\n",
      "iter2200 value 57.447843\n",
      "iter2210 value 57.434887\n",
      "iter2220 value 57.426103\n",
      "iter2230 value 57.418063\n",
      "iter2240 value 57.414003\n",
      "iter2250 value 57.405954\n",
      "iter2260 value 57.401615\n",
      "iter2270 value 57.399556\n",
      "iter2280 value 57.398087\n",
      "iter2290 value 57.384910\n",
      "iter2300 value 57.379059\n",
      "iter2310 value 57.377376\n",
      "iter2320 value 57.371272\n",
      "iter2330 value 57.367808\n",
      "iter2340 value 57.366913\n",
      "iter2350 value 57.365151\n",
      "iter2360 value 57.362279\n",
      "iter2370 value 57.358219\n",
      "iter2380 value 57.355601\n",
      "iter2390 value 57.352878\n",
      "iter2400 value 57.350811\n",
      "iter2410 value 57.348114\n",
      "iter2420 value 57.342732\n",
      "iter2430 value 57.337493\n",
      "iter2440 value 57.333513\n",
      "iter2450 value 57.329099\n",
      "iter2460 value 57.265788\n",
      "iter2470 value 57.237511\n",
      "iter2480 value 57.220512\n",
      "iter2490 value 57.193240\n",
      "iter2500 value 57.138597\n",
      "iter2510 value 57.090459\n",
      "iter2520 value 57.067006\n",
      "iter2530 value 57.057547\n",
      "iter2540 value 57.044858\n",
      "iter2550 value 57.022134\n",
      "iter2560 value 56.980728\n",
      "iter2570 value 56.969355\n",
      "iter2580 value 56.942689\n",
      "iter2590 value 56.935129\n",
      "iter2600 value 56.918467\n",
      "iter2610 value 56.906012\n",
      "iter2620 value 56.878839\n",
      "iter2630 value 56.870575\n",
      "iter2640 value 56.852408\n",
      "iter2650 value 56.845126\n",
      "iter2660 value 56.828030\n",
      "iter2670 value 56.808236\n",
      "iter2680 value 56.793648\n",
      "iter2690 value 56.786155\n",
      "iter2700 value 56.772411\n",
      "iter2710 value 56.766251\n",
      "iter2720 value 56.758569\n",
      "iter2730 value 56.745701\n",
      "iter2740 value 56.739832\n",
      "iter2750 value 56.734411\n",
      "iter2760 value 56.726925\n",
      "iter2770 value 56.722851\n",
      "iter2780 value 56.719417\n",
      "iter2790 value 56.715605\n",
      "iter2800 value 56.711899\n",
      "iter2810 value 56.705594\n",
      "iter2820 value 56.694750\n",
      "iter2830 value 56.690069\n",
      "iter2840 value 56.687934\n",
      "iter2850 value 56.686907\n",
      "iter2860 value 56.685814\n",
      "iter2870 value 56.684942\n",
      "iter2880 value 56.683893\n",
      "iter2890 value 56.682576\n",
      "iter2900 value 56.680902\n",
      "iter2910 value 56.678916\n",
      "iter2920 value 56.677484\n",
      "iter2930 value 56.674080\n",
      "iter2940 value 56.670658\n",
      "iter2950 value 56.658240\n",
      "iter2960 value 56.647786\n",
      "iter2970 value 56.642073\n",
      "iter2980 value 56.639570\n",
      "iter2990 value 56.637621\n",
      "iter3000 value 56.636351\n",
      "final  value 56.636351 \n",
      "stopped after 3000 iterations\n",
      "[1] \"[INFO] - Misclassification rate - 1 fold: 0.0830434782608696\"\n",
      "[1] \"[INFO] - Training set size: 2300 - Testing set size 2301\"\n",
      "# weights:  886\n",
      "initial  value 1601.661837 \n",
      "iter  10 value 1432.694563\n",
      "iter  20 value 889.269880\n",
      "iter  30 value 536.319814\n",
      "iter  40 value 458.872936\n",
      "iter  50 value 434.624938\n",
      "iter  60 value 402.430172\n",
      "iter  70 value 335.681350\n",
      "iter  80 value 266.870108\n",
      "iter  90 value 227.605072\n",
      "iter 100 value 206.089498\n",
      "iter 110 value 184.777510\n",
      "iter 120 value 168.421022\n",
      "iter 130 value 159.809650\n",
      "iter 140 value 148.736877\n",
      "iter 150 value 142.552876\n",
      "iter 160 value 138.059150\n",
      "iter 170 value 131.186452\n",
      "iter 180 value 126.803807\n",
      "iter 190 value 124.202852\n",
      "iter 200 value 122.266627\n",
      "iter 210 value 120.192017\n",
      "iter 220 value 118.148862\n",
      "iter 230 value 117.363514\n",
      "iter 240 value 115.439789\n",
      "iter 250 value 113.004849\n",
      "iter 260 value 110.797776\n",
      "iter 270 value 109.068268\n",
      "iter 280 value 108.375741\n",
      "iter 290 value 107.340520\n",
      "iter 300 value 106.323726\n",
      "iter 310 value 104.070247\n",
      "iter 320 value 103.795167\n",
      "iter 330 value 103.793065\n",
      "iter 340 value 103.792412\n",
      "final  value 103.792408 \n",
      "converged\n",
      "[1] \"[INFO] - Misclassification rate - 2 fold: 0.0912646675358539\"\n",
      "[1] \"[INFO] - CV - Mean misclassification rate: 0.10431822589932\"\n",
      "# weights:  886\n",
      "initial  value 1584.643417 \n",
      "iter  10 value 1388.007801\n",
      "iter  20 value 1296.164192\n",
      "iter  30 value 1173.555450\n",
      "iter  40 value 1138.696424\n",
      "iter  50 value 837.813289\n",
      "iter  60 value 435.067944\n",
      "iter  70 value 341.151831\n",
      "iter  80 value 271.764617\n",
      "iter  90 value 226.105623\n",
      "iter 100 value 190.518441\n",
      "iter 110 value 175.862695\n",
      "iter 120 value 169.794545\n",
      "iter 130 value 158.570579\n",
      "iter 140 value 132.152191\n",
      "iter 150 value 111.499395\n",
      "iter 160 value 92.454497\n",
      "iter 170 value 76.033553\n",
      "iter 180 value 66.177456\n",
      "iter 190 value 59.129985\n",
      "iter 200 value 56.256584\n",
      "iter 210 value 51.908511\n",
      "iter 220 value 51.438397\n",
      "iter 230 value 49.548478\n",
      "iter 240 value 47.876454\n",
      "iter 250 value 46.765735\n",
      "iter 260 value 45.423038\n",
      "iter 270 value 44.385104\n",
      "iter 280 value 43.627211\n",
      "iter 290 value 43.158063\n",
      "iter 300 value 42.858706\n",
      "iter 310 value 42.538646\n",
      "iter 320 value 42.157040\n",
      "iter 330 value 41.837696\n",
      "iter 340 value 41.690395\n",
      "iter 350 value 41.673648\n",
      "iter 360 value 41.640089\n",
      "iter 370 value 41.630307\n",
      "iter 380 value 41.610842\n",
      "iter 390 value 41.542286\n",
      "iter 400 value 41.434898\n",
      "iter 410 value 41.355994\n",
      "iter 420 value 41.270617\n",
      "iter 430 value 41.159400\n",
      "iter 440 value 41.090685\n",
      "iter 450 value 41.066153\n",
      "iter 460 value 41.045323\n",
      "iter 470 value 40.999111\n",
      "iter 480 value 40.962604\n",
      "iter 490 value 40.920309\n",
      "iter 500 value 40.864451\n",
      "iter 510 value 40.781940\n",
      "iter 520 value 40.655748\n",
      "iter 530 value 40.546770\n",
      "iter 540 value 40.289014\n",
      "iter 550 value 40.165500\n",
      "iter 560 value 39.996850\n",
      "iter 570 value 39.855255\n",
      "iter 580 value 39.757525\n",
      "iter 590 value 39.752808\n",
      "iter 600 value 39.720249\n",
      "iter 610 value 39.676310\n",
      "iter 620 value 39.615042\n",
      "iter 630 value 39.572765\n",
      "iter 640 value 39.548088\n",
      "iter 650 value 39.516430\n",
      "iter 660 value 39.502228\n",
      "iter 670 value 39.444355\n",
      "iter 680 value 39.396186\n",
      "iter 690 value 39.342786\n",
      "iter 700 value 39.341972\n",
      "iter 710 value 39.321497\n",
      "iter 720 value 39.303722\n",
      "iter 730 value 39.290949\n",
      "iter 740 value 39.264873\n",
      "iter 750 value 39.220296\n",
      "iter 760 value 39.192506\n",
      "iter 770 value 39.167513\n",
      "iter 780 value 39.137743\n",
      "iter 790 value 39.104880\n",
      "iter 800 value 39.081131\n",
      "iter 810 value 39.062052\n",
      "iter 820 value 39.042841\n",
      "iter 830 value 39.018745\n",
      "iter 840 value 38.984804\n",
      "iter 850 value 38.915441\n",
      "iter 860 value 38.876666\n",
      "iter 870 value 38.856643\n",
      "iter 880 value 38.833779\n",
      "iter 890 value 38.824188\n",
      "iter 900 value 38.817612\n",
      "iter 910 value 38.803914\n",
      "iter 920 value 38.793722\n",
      "iter 930 value 38.781505\n",
      "iter 940 value 38.749518\n",
      "iter 950 value 38.701530\n",
      "iter 960 value 38.679737\n",
      "iter 970 value 38.644834\n",
      "iter 980 value 38.597948\n",
      "iter 990 value 38.517129\n",
      "iter1000 value 38.451800\n",
      "iter1010 value 38.365034\n",
      "iter1020 value 38.306503\n",
      "iter1030 value 38.250367\n",
      "iter1040 value 38.205445\n",
      "iter1050 value 38.171382\n",
      "iter1060 value 38.135715\n",
      "iter1070 value 38.101597\n",
      "iter1080 value 38.075470\n",
      "iter1090 value 38.053513\n",
      "iter1100 value 38.018987\n",
      "iter1110 value 38.002216\n",
      "iter1120 value 37.738308\n",
      "iter1130 value 37.509295\n",
      "iter1140 value 37.381274\n",
      "iter1150 value 37.312044\n",
      "iter1160 value 37.291924\n",
      "iter1170 value 37.273335\n",
      "iter1180 value 37.255514\n",
      "iter1190 value 37.225223\n",
      "iter1200 value 37.083954\n",
      "iter1210 value 36.988951\n",
      "iter1220 value 36.963280\n",
      "iter1230 value 36.951810\n",
      "iter1240 value 36.942679\n",
      "iter1250 value 36.933337\n",
      "iter1260 value 36.926343\n",
      "iter1270 value 36.918258\n",
      "iter1280 value 36.911899\n",
      "iter1290 value 36.905673\n",
      "iter1300 value 36.891399\n",
      "iter1310 value 36.882065\n",
      "iter1320 value 36.870503\n",
      "iter1330 value 36.869195\n",
      "iter1340 value 36.847142\n",
      "iter1350 value 36.827217\n",
      "iter1360 value 36.804837\n",
      "iter1370 value 36.773925\n",
      "iter1380 value 36.759419\n",
      "iter1390 value 36.751916\n",
      "iter1400 value 36.740390\n",
      "iter1410 value 36.724050\n",
      "iter1420 value 36.713231\n",
      "iter1430 value 36.705520\n",
      "iter1440 value 36.698402\n",
      "iter1450 value 36.695334\n",
      "iter1460 value 36.686052\n",
      "iter1470 value 36.631742\n",
      "iter1480 value 36.603839\n",
      "iter1490 value 36.584220\n",
      "iter1500 value 36.572125\n",
      "iter1510 value 36.561820\n",
      "iter1520 value 36.528591\n",
      "iter1530 value 36.497727\n",
      "iter1540 value 36.491926\n",
      "iter1550 value 36.442393\n",
      "iter1560 value 36.420870\n",
      "iter1570 value 36.410243\n",
      "iter1580 value 36.403299\n",
      "iter1590 value 36.395204\n",
      "iter1600 value 36.382927\n",
      "iter1610 value 36.329104\n",
      "iter1620 value 36.258074\n",
      "iter1630 value 36.243115\n",
      "iter1640 value 36.187315\n",
      "iter1650 value 36.121494\n",
      "iter1660 value 36.100005\n",
      "iter1670 value 36.089506\n",
      "iter1680 value 36.082832\n",
      "iter1690 value 36.076759\n",
      "iter1700 value 36.070747\n",
      "iter1710 value 36.064589\n",
      "iter1720 value 36.055258\n",
      "iter1730 value 36.038040\n",
      "iter1740 value 36.015201\n",
      "iter1750 value 36.008487\n",
      "iter1760 value 35.929313\n",
      "iter1770 value 35.780138\n",
      "iter1780 value 35.703006\n",
      "iter1790 value 35.684583\n",
      "iter1800 value 35.666148\n",
      "iter1810 value 35.650490\n",
      "iter1820 value 35.642317\n",
      "iter1830 value 35.634630\n",
      "iter1840 value 35.628205\n",
      "iter1850 value 35.619499\n",
      "iter1860 value 35.612902\n",
      "iter1870 value 35.606857\n",
      "iter1880 value 35.601609\n",
      "iter1890 value 35.597656\n",
      "iter1900 value 35.591779\n",
      "iter1910 value 35.586042\n",
      "iter1920 value 35.584622\n",
      "iter1930 value 35.564559\n",
      "iter1940 value 35.545299\n",
      "iter1950 value 35.536203\n",
      "iter1960 value 35.529838\n",
      "iter1970 value 35.527041\n",
      "iter1980 value 35.524320\n",
      "iter1990 value 35.520386\n",
      "iter2000 value 35.516275\n",
      "iter2010 value 35.510912\n",
      "iter2020 value 35.506569\n",
      "iter2030 value 35.503464\n",
      "iter2040 value 35.499959\n",
      "iter2050 value 35.497246\n",
      "iter2060 value 35.494475\n",
      "iter2070 value 35.492110\n",
      "iter2080 value 35.489212\n",
      "iter2090 value 35.485123\n",
      "iter2100 value 35.480315\n",
      "iter2110 value 35.472231\n",
      "iter2120 value 35.464274\n",
      "iter2130 value 35.459034\n",
      "iter2140 value 35.455350\n",
      "iter2150 value 35.451047\n",
      "iter2160 value 35.446230\n",
      "iter2170 value 35.442741\n",
      "iter2180 value 35.439752\n",
      "iter2190 value 35.436319\n",
      "iter2200 value 35.434205\n",
      "iter2210 value 35.432095\n",
      "iter2220 value 35.429809\n",
      "iter2230 value 35.427605\n",
      "iter2240 value 35.425210\n",
      "iter2250 value 35.420655\n",
      "iter2260 value 35.419345\n",
      "iter2270 value 35.397798\n",
      "iter2280 value 35.384820\n",
      "iter2290 value 35.380877\n",
      "iter2300 value 35.376248\n",
      "iter2310 value 35.372640\n",
      "iter2320 value 35.369443\n",
      "iter2330 value 35.366960\n",
      "iter2340 value 35.364945\n",
      "iter2350 value 35.362779\n",
      "iter2360 value 35.360818\n",
      "iter2370 value 35.359549\n",
      "iter2380 value 35.358092\n",
      "iter2390 value 35.356758\n",
      "iter2400 value 35.354523\n",
      "iter2410 value 35.352611\n",
      "iter2420 value 35.350614\n",
      "iter2430 value 35.345716\n",
      "iter2440 value 35.343807\n",
      "iter2450 value 35.341955\n",
      "iter2460 value 35.340197\n",
      "iter2470 value 35.336924\n",
      "iter2480 value 35.334622\n",
      "iter2490 value 35.333067\n",
      "iter2500 value 35.316009\n",
      "iter2510 value 35.288688\n",
      "iter2520 value 35.252796\n",
      "iter2530 value 35.233172\n",
      "iter2540 value 35.208541\n",
      "iter2550 value 35.112264\n",
      "iter2560 value 35.059736\n",
      "iter2570 value 35.033907\n",
      "iter2580 value 35.006982\n",
      "iter2590 value 34.992210\n",
      "iter2600 value 34.976686\n",
      "iter2610 value 34.920972\n",
      "iter2620 value 34.888187\n",
      "iter2630 value 34.874996\n",
      "iter2640 value 34.860538\n",
      "iter2650 value 34.842790\n",
      "iter2660 value 34.830358\n",
      "iter2670 value 34.821072\n",
      "iter2680 value 34.816306\n",
      "iter2690 value 34.813120\n",
      "iter2700 value 34.809903\n",
      "iter2710 value 34.805469\n",
      "iter2720 value 34.801336\n",
      "iter2730 value 34.798813\n",
      "iter2740 value 34.795499\n",
      "iter2750 value 34.784783\n",
      "iter2760 value 34.741818\n",
      "iter2770 value 34.733718\n",
      "iter2780 value 34.729980\n",
      "iter2790 value 34.727577\n",
      "iter2800 value 34.725617\n",
      "iter2810 value 34.723623\n",
      "iter2820 value 34.720485\n",
      "iter2830 value 34.717807\n",
      "iter2840 value 34.714936\n",
      "iter2850 value 34.713162\n",
      "iter2860 value 34.710423\n",
      "iter2870 value 34.707850\n",
      "iter2880 value 34.705083\n",
      "iter2890 value 34.702387\n",
      "iter2900 value 34.699794\n",
      "iter2910 value 34.698210\n",
      "iter2920 value 34.696234\n",
      "iter2930 value 34.693596\n",
      "iter2940 value 34.691252\n",
      "iter2950 value 34.689139\n",
      "iter2960 value 34.687358\n",
      "iter2970 value 34.685738\n",
      "iter2980 value 34.681879\n",
      "iter2990 value 34.677094\n",
      "iter3000 value 34.651425\n",
      "final  value 34.651425 \n",
      "stopped after 3000 iterations\n",
      "[1] \"[INFO] - Confusion matrix In sample :\"\n",
      "       \n",
      "Y_hat   FALSE TRUE\n",
      "  FALSE  1387    4\n",
      "  TRUE      6  903\n",
      "[1] \"[INFO] - Misclassification rate In sample : 0.0043478260869565\"\n",
      "[1] \"[INFO] - Confusion matrix Out sample :\"\n",
      "       \n",
      "Y_hat   FALSE TRUE\n",
      "  FALSE  1309   89\n",
      "  TRUE     86  817\n",
      "[1] \"[INFO] - Misclassification rate Out sample : 0.0760538896132117\"\n",
      "[1] \"[INFO] - Training set size: 2301 - Testing set size 2300\"\n",
      "# weights:  1771\n",
      "initial  value 1596.127538 \n",
      "iter  10 value 1353.089793\n",
      "iter  20 value 1146.026858\n",
      "iter  30 value 1076.621974\n",
      "iter  40 value 933.661918\n",
      "iter  50 value 844.565208\n",
      "iter  60 value 531.286446\n",
      "iter  70 value 383.042346\n",
      "iter  80 value 302.629616\n",
      "iter  90 value 230.256171\n",
      "iter 100 value 155.989898\n",
      "iter 110 value 102.994098\n",
      "iter 120 value 71.326370\n",
      "iter 130 value 44.413606\n",
      "iter 140 value 35.118240\n",
      "iter 150 value 24.756878\n",
      "iter 160 value 19.284706\n",
      "iter 170 value 18.131049\n",
      "iter 180 value 17.223724\n",
      "iter 190 value 16.682735\n",
      "iter 200 value 16.272978\n",
      "iter 210 value 15.676888\n",
      "iter 220 value 15.358052\n",
      "iter 230 value 15.183765\n",
      "iter 240 value 14.947320\n",
      "iter 250 value 14.564702\n",
      "iter 260 value 14.070306\n",
      "iter 270 value 13.609237\n",
      "iter 280 value 13.492526\n",
      "iter 290 value 13.465017\n",
      "iter 300 value 13.459012\n",
      "iter 310 value 13.458112\n",
      "iter 320 value 13.457567\n",
      "iter 330 value 13.457341\n",
      "iter 340 value 13.456896\n",
      "iter 350 value 13.456724\n",
      "iter 360 value 13.456647\n",
      "iter 370 value 13.456636\n",
      "iter 380 value 13.456585\n",
      "iter 390 value 13.456576\n",
      "final  value 13.456568 \n",
      "converged\n",
      "[1] \"[INFO] - Misclassification rate - 1 fold: 0.0921739130434782\"\n",
      "[1] \"[INFO] - Training set size: 2300 - Testing set size 2301\"\n",
      "# weights:  1771\n",
      "initial  value 1664.702570 \n",
      "iter  10 value 1402.701955\n",
      "iter  20 value 1279.741097\n",
      "iter  30 value 1230.205814\n",
      "iter  40 value 835.816519\n",
      "iter  50 value 750.129851\n",
      "iter  60 value 698.215699\n",
      "iter  70 value 500.219956\n",
      "iter  80 value 396.858440\n",
      "iter  90 value 384.087273\n",
      "iter 100 value 349.576503\n",
      "iter 110 value 327.808502\n",
      "iter 120 value 296.390807\n",
      "iter 130 value 263.001226\n",
      "iter 140 value 257.564928\n",
      "iter 150 value 247.148866\n",
      "iter 160 value 229.418490\n",
      "iter 170 value 200.046743\n",
      "iter 180 value 163.919647\n",
      "iter 190 value 120.034773\n",
      "iter 200 value 86.249478\n",
      "iter 210 value 58.664360\n",
      "iter 220 value 44.905662\n",
      "iter 230 value 37.783699\n",
      "iter 240 value 34.185978\n",
      "iter 250 value 32.608428\n",
      "iter 260 value 30.624361\n",
      "iter 270 value 28.113154\n",
      "iter 280 value 26.702421\n",
      "iter 290 value 25.669470\n",
      "iter 300 value 25.032986\n",
      "iter 310 value 24.836671\n",
      "iter 320 value 24.157195\n",
      "iter 330 value 23.096331\n",
      "iter 340 value 22.222343\n",
      "iter 350 value 21.551712\n",
      "iter 360 value 20.978344\n",
      "iter 370 value 20.476153\n",
      "iter 380 value 20.131555\n",
      "iter 390 value 19.689702\n",
      "iter 400 value 19.437610\n",
      "iter 410 value 19.066927\n",
      "iter 420 value 18.843148\n",
      "iter 430 value 18.503559\n",
      "iter 440 value 18.280177\n",
      "iter 450 value 18.083821\n",
      "iter 460 value 17.845239\n",
      "iter 470 value 17.814121\n",
      "iter 480 value 17.788120\n",
      "iter 490 value 17.694772\n",
      "iter 500 value 17.663542\n",
      "iter 510 value 17.650434\n",
      "iter 520 value 17.640102\n",
      "iter 530 value 17.631527\n",
      "iter 540 value 17.619011\n",
      "iter 550 value 17.581080\n",
      "iter 560 value 17.180245\n",
      "iter 570 value 16.495051\n",
      "iter 580 value 16.387107\n",
      "iter 590 value 16.217594\n",
      "iter 600 value 15.895067\n",
      "iter 610 value 15.839291\n",
      "iter 620 value 15.510872\n",
      "iter 630 value 14.382836\n",
      "iter 640 value 14.126139\n",
      "iter 650 value 14.058275\n",
      "iter 660 value 13.956961\n",
      "iter 670 value 13.940631\n",
      "iter 680 value 13.835004\n",
      "iter 690 value 13.770219\n",
      "iter 700 value 13.766424\n",
      "iter 710 value 13.764474\n",
      "iter 720 value 13.763020\n",
      "iter 730 value 13.761992\n",
      "iter 740 value 13.760723\n",
      "iter 750 value 13.759670\n",
      "iter 760 value 13.758793\n",
      "iter 770 value 13.755693\n",
      "iter 780 value 13.712630\n",
      "iter 790 value 13.598833\n",
      "iter 800 value 13.489562\n",
      "iter 810 value 13.452131\n",
      "iter 820 value 13.387498\n",
      "iter 830 value 13.374813\n",
      "iter 840 value 13.364638\n",
      "iter 850 value 13.360729\n",
      "iter 860 value 13.358967\n",
      "iter 870 value 13.357582\n",
      "iter 880 value 13.356540\n",
      "iter 890 value 13.355512\n",
      "iter 900 value 13.354747\n",
      "iter 910 value 13.354047\n",
      "iter 920 value 13.353629\n",
      "iter 930 value 13.353269\n",
      "iter 940 value 13.352842\n",
      "iter 950 value 13.352459\n",
      "iter 960 value 13.351796\n",
      "iter 970 value 13.351292\n",
      "iter 980 value 13.350907\n",
      "iter 990 value 13.350662\n",
      "iter1000 value 13.350448\n",
      "iter1010 value 13.350120\n",
      "iter1020 value 13.349872\n",
      "iter1030 value 13.349474\n",
      "iter1040 value 13.348900\n",
      "iter1050 value 13.348432\n",
      "iter1060 value 13.347835\n",
      "iter1070 value 13.347117\n",
      "iter1080 value 13.343932\n",
      "iter1090 value 13.318124\n",
      "iter1100 value 13.230272\n",
      "iter1110 value 13.093603\n",
      "iter1120 value 13.062230\n",
      "iter1130 value 13.056991\n",
      "iter1140 value 13.055621\n",
      "iter1150 value 13.054474\n",
      "iter1160 value 13.047870\n",
      "iter1170 value 12.900354\n",
      "iter1180 value 12.832619\n",
      "iter1190 value 12.823563\n",
      "iter1200 value 12.819373\n",
      "iter1210 value 12.816620\n",
      "iter1220 value 12.815471\n",
      "iter1230 value 12.814967\n",
      "iter1240 value 12.813935\n",
      "iter1250 value 12.813395\n",
      "iter1260 value 12.812854\n",
      "iter1270 value 12.812676\n",
      "iter1280 value 12.812336\n",
      "iter1290 value 12.811363\n",
      "iter1300 value 12.804905\n",
      "iter1310 value 12.778430\n",
      "iter1320 value 12.627824\n",
      "iter1330 value 12.526855\n",
      "iter1340 value 12.508508\n",
      "iter1350 value 12.468969\n",
      "iter1360 value 12.282426\n",
      "iter1370 value 12.191370\n",
      "iter1380 value 12.181796\n",
      "iter1390 value 12.179551\n",
      "iter1400 value 12.178443\n",
      "iter1410 value 12.176942\n",
      "iter1420 value 12.176066\n",
      "iter1430 value 12.175577\n",
      "iter1440 value 12.175082\n",
      "iter1450 value 12.174811\n",
      "iter1460 value 12.174363\n",
      "iter1470 value 12.174055\n",
      "iter1480 value 12.173771\n",
      "iter1490 value 12.173582\n",
      "iter1500 value 12.173442\n",
      "iter1510 value 12.173304\n",
      "iter1520 value 12.173184\n",
      "iter1530 value 12.173093\n",
      "iter1540 value 12.173002\n",
      "iter1550 value 12.172922\n",
      "iter1560 value 12.172805\n",
      "iter1570 value 12.172634\n",
      "iter1580 value 12.172541\n",
      "iter1590 value 12.172369\n",
      "iter1600 value 12.172218\n",
      "iter1610 value 12.172082\n",
      "iter1620 value 12.171817\n",
      "iter1630 value 12.171262\n",
      "iter1640 value 12.169307\n",
      "iter1650 value 12.165212\n",
      "iter1660 value 12.152944\n",
      "iter1670 value 12.133642\n",
      "iter1680 value 12.058493\n",
      "iter1690 value 11.402833\n",
      "iter1700 value 10.659579\n",
      "iter1710 value 10.052384\n",
      "iter1720 value 9.925082\n",
      "iter1730 value 9.908966\n",
      "iter1740 value 9.901398\n",
      "iter1750 value 9.898381\n",
      "iter1760 value 9.896120\n",
      "iter1770 value 9.894449\n",
      "iter1780 value 9.893393\n",
      "iter1790 value 9.892669\n",
      "iter1800 value 9.892210\n",
      "iter1810 value 9.891848\n",
      "iter1820 value 9.891597\n",
      "iter1830 value 9.891217\n",
      "iter1840 value 9.890902\n",
      "iter1850 value 9.890703\n",
      "iter1860 value 9.890508\n",
      "iter1870 value 9.890379\n",
      "iter1880 value 9.890161\n",
      "iter1890 value 9.890012\n",
      "iter1900 value 9.889855\n",
      "iter1910 value 9.889695\n",
      "iter1920 value 9.889578\n",
      "iter1930 value 9.889359\n",
      "iter1940 value 9.889277\n",
      "iter1950 value 9.889160\n",
      "iter1960 value 9.889099\n",
      "iter1970 value 9.889060\n",
      "iter1980 value 9.888992\n",
      "iter1990 value 9.888899\n",
      "iter2000 value 9.888847\n",
      "iter2010 value 9.888775\n",
      "iter2010 value 9.888775\n",
      "iter2010 value 9.888775\n",
      "final  value 9.888775 \n",
      "converged\n",
      "[1] \"[INFO] - Misclassification rate - 2 fold: 0.0743155149934811\"\n",
      "[1] \"[INFO] - CV - Mean misclassification rate: 0.103536354123343\"\n",
      "# weights:  1771\n",
      "initial  value 1632.524816 \n",
      "iter  10 value 1426.159087\n",
      "iter  20 value 1338.931658\n",
      "iter  30 value 1087.080685\n",
      "iter  40 value 940.763980\n",
      "iter  50 value 652.115137\n",
      "iter  60 value 468.588254\n",
      "iter  70 value 405.763244\n",
      "iter  80 value 353.715665\n",
      "iter  90 value 341.987913\n",
      "iter 100 value 333.794141\n",
      "iter 110 value 330.865367\n",
      "iter 120 value 322.372170\n",
      "iter 130 value 280.687727\n",
      "iter 140 value 250.199132\n",
      "iter 150 value 203.684624\n",
      "iter 160 value 159.928436\n",
      "iter 170 value 119.735978\n",
      "iter 180 value 93.872886\n",
      "iter 190 value 81.914170\n",
      "iter 200 value 73.331123\n",
      "iter 210 value 70.005694\n",
      "iter 220 value 67.658931\n",
      "iter 230 value 65.176956\n",
      "iter 240 value 64.407445\n",
      "iter 250 value 62.772495\n",
      "iter 260 value 61.860576\n",
      "iter 270 value 61.116057\n",
      "iter 280 value 60.108832\n",
      "iter 290 value 59.904210\n",
      "iter 300 value 59.306052\n",
      "iter 310 value 58.972534\n",
      "iter 320 value 58.832320\n",
      "iter 330 value 58.694753\n",
      "iter 340 value 58.535080\n",
      "iter 350 value 58.485563\n",
      "iter 360 value 58.299222\n",
      "iter 370 value 58.227279\n",
      "iter 380 value 58.180666\n",
      "iter 390 value 58.139734\n",
      "iter 400 value 58.048735\n",
      "iter 410 value 57.997742\n",
      "iter 420 value 57.983753\n",
      "iter 430 value 57.729272\n",
      "iter 440 value 57.522169\n",
      "iter 450 value 57.478814\n",
      "iter 460 value 57.448514\n",
      "iter 470 value 57.432659\n",
      "iter 480 value 57.415489\n",
      "iter 490 value 57.396500\n",
      "iter 500 value 57.384599\n",
      "iter 510 value 57.364872\n",
      "iter 520 value 57.349572\n",
      "iter 530 value 57.329858\n",
      "iter 540 value 57.284622\n",
      "iter 550 value 57.185775\n",
      "iter 560 value 57.097156\n",
      "iter 570 value 57.082146\n",
      "iter 580 value 57.057224\n",
      "iter 590 value 57.026573\n",
      "iter 600 value 56.974912\n",
      "iter 610 value 56.940913\n",
      "iter 620 value 56.921439\n",
      "iter 630 value 56.904301\n",
      "iter 640 value 56.890234\n",
      "iter 650 value 56.869583\n",
      "iter 660 value 56.858075\n",
      "iter 670 value 56.853614\n",
      "iter 680 value 56.833886\n",
      "iter 690 value 56.823722\n",
      "iter 700 value 56.719237\n",
      "iter 710 value 56.698037\n",
      "iter 720 value 56.684565\n",
      "iter 730 value 56.679575\n",
      "iter 740 value 56.674239\n",
      "iter 750 value 56.664569\n",
      "iter 760 value 56.658184\n",
      "iter 770 value 56.646676\n",
      "iter 780 value 56.619401\n",
      "iter 790 value 56.593193\n",
      "iter 800 value 56.589211\n",
      "iter 810 value 56.582260\n",
      "iter 820 value 56.557662\n",
      "iter 830 value 56.543716\n",
      "iter 840 value 56.531506\n",
      "iter 850 value 56.522108\n",
      "iter 860 value 56.515000\n",
      "iter 870 value 56.502264\n",
      "iter 880 value 56.501054\n",
      "iter 890 value 56.498829\n",
      "iter 900 value 56.494034\n",
      "iter 910 value 56.463614\n",
      "iter 920 value 56.447337\n",
      "iter 930 value 56.420222\n",
      "iter 940 value 56.410565\n",
      "iter 950 value 56.402612\n",
      "iter 960 value 56.389277\n",
      "iter 970 value 56.372315\n",
      "iter 980 value 56.364602\n",
      "iter 990 value 56.358793\n",
      "iter1000 value 56.351967\n",
      "iter1010 value 56.340214\n",
      "iter1020 value 56.327102\n",
      "iter1030 value 56.313940\n",
      "iter1040 value 56.298627\n",
      "iter1050 value 56.277541\n",
      "iter1060 value 56.258934\n",
      "iter1070 value 56.236328\n",
      "iter1080 value 56.206529\n",
      "iter1090 value 56.183786\n",
      "iter1100 value 56.179511\n",
      "iter1110 value 56.170464\n",
      "iter1120 value 56.162195\n",
      "iter1130 value 56.154210\n",
      "iter1140 value 56.149975\n",
      "iter1150 value 56.146438\n",
      "iter1160 value 56.140947\n",
      "iter1170 value 56.135042\n",
      "iter1180 value 56.119891\n",
      "iter1190 value 56.070246\n",
      "iter1200 value 56.036787\n",
      "iter1210 value 55.871272\n",
      "iter1220 value 55.784300\n",
      "iter1230 value 55.752973\n",
      "iter1240 value 55.731672\n",
      "iter1250 value 55.695436\n",
      "iter1260 value 55.635059\n",
      "iter1270 value 55.596161\n",
      "iter1280 value 55.585247\n",
      "iter1290 value 55.579178\n",
      "iter1300 value 55.566440\n",
      "iter1310 value 55.553583\n",
      "iter1320 value 55.544940\n",
      "iter1330 value 55.538123\n",
      "iter1340 value 55.512896\n",
      "iter1350 value 55.483936\n",
      "iter1360 value 55.457794\n",
      "iter1370 value 55.444750\n",
      "iter1380 value 55.415216\n",
      "iter1390 value 55.358554\n",
      "iter1400 value 55.341568\n",
      "iter1410 value 55.328657\n",
      "iter1420 value 55.323183\n",
      "iter1430 value 55.311857\n",
      "iter1440 value 55.266502\n",
      "iter1450 value 55.246737\n",
      "iter1460 value 55.233629\n",
      "iter1470 value 55.207259\n",
      "iter1480 value 55.166371\n",
      "iter1490 value 55.070179\n",
      "iter1500 value 55.042919\n",
      "iter1510 value 55.026569\n",
      "iter1520 value 55.018197\n",
      "iter1530 value 55.016138\n",
      "iter1540 value 55.014452\n",
      "iter1550 value 55.011044\n",
      "iter1560 value 55.007501\n",
      "iter1570 value 54.996586\n",
      "iter1580 value 54.971930\n",
      "iter1590 value 54.959881\n",
      "iter1600 value 54.954302\n",
      "iter1610 value 54.946534\n",
      "iter1620 value 54.942231\n",
      "iter1630 value 54.911889\n",
      "iter1640 value 54.895379\n",
      "iter1650 value 54.789752\n",
      "iter1660 value 54.608488\n",
      "iter1670 value 54.598013\n",
      "iter1680 value 54.594398\n",
      "iter1690 value 54.591741\n",
      "iter1700 value 54.588734\n",
      "iter1710 value 54.584887\n",
      "iter1720 value 54.582060\n",
      "iter1730 value 54.577371\n",
      "iter1740 value 54.571030\n",
      "iter1750 value 54.563285\n",
      "iter1760 value 54.555949\n",
      "iter1770 value 54.546958\n",
      "iter1780 value 54.539290\n",
      "iter1790 value 54.521209\n",
      "iter1800 value 54.515226\n",
      "iter1810 value 54.498533\n",
      "iter1820 value 54.482380\n",
      "iter1830 value 54.474187\n",
      "iter1840 value 54.467883\n",
      "iter1850 value 54.462306\n",
      "iter1860 value 54.456580\n",
      "iter1870 value 54.452153\n",
      "iter1880 value 54.448225\n",
      "iter1890 value 54.440861\n",
      "iter1900 value 54.433832\n",
      "iter1910 value 54.358846\n",
      "iter1920 value 54.239389\n",
      "iter1930 value 54.173158\n",
      "iter1940 value 54.156664\n",
      "iter1950 value 54.148019\n",
      "iter1960 value 54.139046\n",
      "iter1970 value 54.134097\n",
      "iter1980 value 54.129918\n",
      "iter1990 value 54.125555\n",
      "iter2000 value 54.120593\n",
      "iter2010 value 54.117649\n",
      "iter2020 value 54.113550\n",
      "iter2030 value 54.110542\n",
      "iter2040 value 54.105341\n",
      "iter2050 value 54.098463\n",
      "iter2060 value 54.092471\n",
      "iter2070 value 54.085933\n",
      "iter2080 value 54.076106\n",
      "iter2090 value 54.068177\n",
      "iter2100 value 54.054687\n",
      "iter2110 value 54.054165\n",
      "iter2120 value 53.998908\n",
      "iter2130 value 53.915096\n",
      "iter2140 value 53.901705\n",
      "iter2150 value 53.897202\n",
      "iter2160 value 53.892562\n",
      "iter2170 value 53.888960\n",
      "iter2180 value 53.886175\n",
      "iter2190 value 53.883370\n",
      "iter2200 value 53.881043\n",
      "iter2210 value 53.879484\n",
      "iter2220 value 53.877191\n",
      "iter2230 value 53.874190\n",
      "iter2240 value 53.871280\n",
      "iter2250 value 53.865549\n",
      "iter2260 value 53.862208\n",
      "iter2270 value 53.859296\n",
      "iter2280 value 53.856575\n",
      "iter2290 value 53.853764\n",
      "iter2300 value 53.850020\n",
      "iter2310 value 53.847075\n",
      "iter2320 value 53.841879\n",
      "iter2330 value 53.837370\n",
      "iter2340 value 53.833146\n",
      "iter2350 value 53.828500\n",
      "iter2360 value 53.823944\n",
      "iter2370 value 53.820107\n",
      "iter2380 value 53.815820\n",
      "iter2390 value 53.810421\n",
      "iter2400 value 53.805857\n",
      "iter2410 value 53.796654\n",
      "iter2420 value 53.790315\n",
      "iter2430 value 53.776355\n",
      "iter2440 value 53.758973\n",
      "iter2450 value 53.756365\n",
      "iter2460 value 53.753096\n",
      "iter2470 value 53.751001\n",
      "iter2480 value 53.749474\n",
      "iter2490 value 53.747987\n",
      "iter2500 value 53.746383\n",
      "iter2510 value 53.745375\n",
      "iter2520 value 53.744064\n",
      "iter2530 value 53.742899\n",
      "iter2540 value 53.741798\n",
      "iter2550 value 53.740288\n",
      "iter2560 value 53.738159\n",
      "iter2570 value 53.736061\n",
      "iter2580 value 53.722378\n",
      "iter2590 value 53.700787\n",
      "iter2600 value 53.691370\n",
      "iter2610 value 53.685493\n",
      "iter2620 value 53.681616\n",
      "iter2630 value 53.679882\n",
      "iter2640 value 53.642102\n",
      "iter2650 value 53.450864\n",
      "iter2660 value 53.394654\n",
      "iter2670 value 53.389602\n",
      "iter2680 value 53.385833\n",
      "iter2690 value 53.382895\n",
      "iter2700 value 53.381769\n",
      "iter2710 value 53.380170\n",
      "iter2720 value 53.378615\n",
      "iter2730 value 53.377451\n",
      "iter2740 value 53.375421\n",
      "iter2750 value 53.367768\n",
      "iter2760 value 53.343290\n",
      "iter2770 value 53.137472\n",
      "iter2780 value 53.081782\n",
      "iter2790 value 53.069374\n",
      "iter2800 value 53.064338\n",
      "iter2810 value 53.062452\n",
      "iter2820 value 53.060567\n",
      "iter2830 value 53.058295\n",
      "iter2840 value 53.049989\n",
      "iter2850 value 53.043000\n",
      "iter2860 value 53.041030\n",
      "iter2870 value 53.039824\n",
      "iter2880 value 53.038681\n",
      "iter2890 value 53.037966\n",
      "iter2900 value 53.036772\n",
      "iter2910 value 53.035245\n",
      "iter2920 value 53.033960\n",
      "iter2930 value 53.027996\n",
      "iter2940 value 53.025794\n",
      "iter2950 value 53.012525\n",
      "iter2960 value 53.006600\n",
      "iter2970 value 53.003263\n",
      "iter2980 value 53.001073\n",
      "iter2990 value 52.998150\n",
      "iter3000 value 52.996234\n",
      "final  value 52.996234 \n",
      "stopped after 3000 iterations\n",
      "[1] \"[INFO] - Confusion matrix In sample :\"\n",
      "       \n",
      "Y_hat   FALSE TRUE\n",
      "  FALSE  1376    5\n",
      "  TRUE      9  910\n",
      "[1] \"[INFO] - Misclassification rate In sample : 0.00608695652173918\"\n",
      "[1] \"[INFO] - Confusion matrix Out sample :\"\n",
      "       \n",
      "Y_hat   FALSE TRUE\n",
      "  FALSE  1327   84\n",
      "  TRUE     76  814\n",
      "[1] \"[INFO] - Misclassification rate Out sample : 0.069534984789222\"\n",
      "[1] \"[INFO] - Training set size: 2301 - Testing set size 2300\"\n",
      "# weights:  2951\n",
      "initial  value 1661.407164 \n",
      "iter  10 value 1360.430428\n",
      "iter  20 value 1098.126545\n",
      "iter  30 value 875.680573\n",
      "iter  40 value 544.613356\n",
      "iter  50 value 516.596876\n",
      "iter  60 value 503.866913\n",
      "iter  70 value 458.002045\n",
      "iter  80 value 385.204572\n",
      "iter  90 value 326.761623\n",
      "iter 100 value 252.244235\n",
      "iter 110 value 182.042862\n",
      "iter 120 value 135.992132\n",
      "iter 130 value 101.834466\n",
      "iter 140 value 92.876902\n",
      "iter 150 value 91.058257\n",
      "iter 160 value 88.185625\n",
      "iter 170 value 87.383511\n",
      "iter 180 value 83.665163\n",
      "iter 190 value 72.244436\n",
      "iter 200 value 62.289188\n",
      "iter 210 value 52.331489\n",
      "iter 220 value 44.005750\n",
      "iter 230 value 38.128784\n",
      "iter 240 value 31.894826\n",
      "iter 250 value 28.990150\n",
      "iter 260 value 26.860502\n",
      "iter 270 value 24.445964\n",
      "iter 280 value 23.118370\n",
      "iter 290 value 21.027911\n",
      "iter 300 value 19.976164\n",
      "iter 310 value 19.710887\n",
      "iter 320 value 19.670488\n",
      "iter 330 value 19.573210\n",
      "iter 340 value 19.493413\n",
      "iter 350 value 19.422285\n",
      "iter 360 value 19.382772\n",
      "iter 370 value 19.367738\n",
      "iter 380 value 19.304986\n",
      "iter 390 value 19.246974\n",
      "iter 400 value 19.181574\n",
      "iter 410 value 19.130406\n",
      "iter 420 value 19.103613\n",
      "iter 430 value 19.063601\n",
      "iter 440 value 19.021440\n",
      "iter 450 value 18.772019\n",
      "iter 460 value 18.650452\n",
      "iter 470 value 18.636211\n",
      "iter 480 value 18.331242\n",
      "iter 490 value 18.210506\n",
      "iter 500 value 18.106153\n",
      "iter 510 value 18.042253\n",
      "iter 520 value 17.307508\n",
      "iter 530 value 15.669582\n",
      "iter 540 value 15.048375\n",
      "iter 550 value 14.387296\n",
      "iter 560 value 14.280128\n",
      "iter 570 value 14.216617\n",
      "iter 580 value 14.144848\n",
      "iter 590 value 14.094310\n",
      "iter 600 value 14.035203\n",
      "iter 610 value 13.978960\n",
      "iter 620 value 13.948671\n",
      "iter 630 value 13.922974\n",
      "iter 640 value 13.915162\n",
      "iter 650 value 13.894194\n",
      "iter 660 value 13.809630\n",
      "iter 670 value 13.535041\n",
      "iter 680 value 12.845395\n",
      "iter 690 value 12.657972\n",
      "iter 700 value 12.536471\n",
      "iter 710 value 12.494903\n",
      "iter 720 value 12.468033\n",
      "iter 730 value 12.452637\n",
      "iter 740 value 12.439055\n",
      "iter 750 value 12.416074\n",
      "iter 760 value 12.384122\n",
      "iter 770 value 12.197409\n",
      "iter 780 value 12.154612\n",
      "iter 790 value 12.128582\n",
      "iter 800 value 12.085325\n",
      "iter 810 value 12.032553\n",
      "iter 820 value 11.995560\n",
      "iter 830 value 11.945881\n",
      "iter 840 value 11.942627\n",
      "iter 850 value 11.905291\n",
      "iter 860 value 11.878931\n",
      "iter 870 value 11.856609\n",
      "iter 880 value 11.800756\n",
      "iter 890 value 11.685974\n",
      "iter 900 value 11.552461\n",
      "iter 910 value 11.513645\n",
      "iter 920 value 11.477009\n",
      "iter 930 value 11.413763\n",
      "iter 940 value 11.407912\n",
      "iter 950 value 11.389190\n",
      "iter 960 value 11.364786\n",
      "iter 970 value 11.319264\n",
      "iter 980 value 11.245379\n",
      "iter 990 value 11.227223\n",
      "iter1000 value 11.205376\n",
      "iter1010 value 11.185323\n",
      "iter1020 value 11.158431\n",
      "iter1030 value 11.131236\n",
      "iter1040 value 11.123033\n",
      "iter1050 value 11.118217\n",
      "iter1060 value 10.968797\n",
      "iter1070 value 10.895313\n",
      "iter1080 value 10.833246\n",
      "iter1090 value 10.607174\n",
      "iter1100 value 10.591970\n",
      "iter1110 value 10.586444\n",
      "iter1120 value 10.581188\n",
      "iter1130 value 10.577383\n",
      "iter1140 value 10.568830\n",
      "iter1150 value 10.550463\n",
      "iter1160 value 10.522546\n",
      "iter1170 value 10.492659\n",
      "iter1180 value 10.469244\n",
      "iter1190 value 10.443992\n",
      "iter1200 value 10.417781\n",
      "iter1210 value 10.390636\n",
      "iter1220 value 10.377191\n",
      "iter1230 value 10.353359\n",
      "iter1240 value 10.320240\n",
      "iter1250 value 10.285068\n",
      "iter1260 value 10.247515\n",
      "iter1270 value 10.218686\n",
      "iter1280 value 10.175848\n",
      "iter1290 value 10.159129\n",
      "iter1300 value 10.126006\n",
      "iter1310 value 10.021415\n",
      "iter1320 value 10.014518\n",
      "iter1330 value 10.013594\n",
      "iter1340 value 10.012591\n",
      "final  value 10.010026 \n",
      "converged\n",
      "[1] \"[INFO] - Misclassification rate - 1 fold: 0.0808695652173913\"\n",
      "[1] \"[INFO] - Training set size: 2300 - Testing set size 2301\"\n",
      "# weights:  2951\n",
      "initial  value 1938.914173 \n",
      "iter  10 value 1399.841318\n",
      "iter  20 value 1130.533681\n",
      "iter  30 value 1087.078695\n",
      "iter  40 value 854.614756\n",
      "iter  50 value 538.594731\n",
      "iter  60 value 453.042155\n",
      "iter  70 value 367.622224\n",
      "iter  80 value 318.910350\n",
      "iter  90 value 261.474049\n",
      "iter 100 value 212.242382\n",
      "iter 110 value 167.610149\n",
      "iter 120 value 130.412819\n",
      "iter 130 value 102.344549\n",
      "iter 140 value 98.847295\n",
      "iter 150 value 97.442085\n",
      "iter 160 value 94.546370\n",
      "iter 170 value 93.368710\n",
      "iter 180 value 92.808121\n",
      "iter 190 value 91.294912\n",
      "iter 200 value 85.318865\n",
      "iter 210 value 75.464476\n",
      "iter 220 value 65.808313\n",
      "iter 230 value 63.052035\n",
      "iter 240 value 62.618607\n",
      "iter 250 value 62.125086\n",
      "iter 260 value 60.881327\n",
      "iter 270 value 53.624906\n",
      "iter 280 value 45.538578\n",
      "iter 290 value 38.250872\n",
      "iter 300 value 34.143320\n",
      "iter 310 value 28.045146\n",
      "iter 320 value 17.987288\n",
      "iter 330 value 11.107367\n",
      "iter 340 value 8.534141\n",
      "iter 350 value 6.070273\n",
      "iter 360 value 5.005521\n",
      "iter 370 value 4.509074\n",
      "iter 380 value 4.275347\n",
      "iter 390 value 4.165371\n",
      "iter 400 value 3.928352\n",
      "iter 410 value 3.704781\n",
      "iter 420 value 3.615536\n",
      "iter 430 value 3.568595\n",
      "iter 440 value 3.532047\n",
      "iter 450 value 3.489497\n",
      "iter 460 value 3.445977\n",
      "iter 470 value 3.119024\n",
      "iter 480 value 2.385569\n",
      "iter 490 value 2.169525\n",
      "iter 500 value 2.069285\n",
      "iter 510 value 2.020889\n",
      "iter 520 value 1.995015\n",
      "iter 530 value 1.977180\n",
      "iter 540 value 1.965247\n",
      "iter 550 value 1.951058\n",
      "iter 560 value 1.942102\n",
      "iter 570 value 1.936500\n",
      "iter 580 value 1.932716\n",
      "iter 590 value 1.930787\n",
      "iter 600 value 1.926656\n",
      "iter 610 value 1.923797\n",
      "iter 620 value 1.921667\n",
      "iter 630 value 1.920263\n",
      "iter 640 value 1.918864\n",
      "iter 650 value 1.917872\n",
      "iter 660 value 1.916631\n",
      "iter 670 value 1.915518\n",
      "iter 680 value 1.914686\n",
      "iter 690 value 1.913850\n",
      "iter 700 value 1.912926\n",
      "iter 710 value 1.912275\n",
      "iter 720 value 1.911876\n",
      "iter 730 value 1.911239\n",
      "iter 740 value 1.908753\n",
      "iter 750 value 1.903127\n",
      "iter 760 value 1.894479\n",
      "iter 770 value 1.889834\n",
      "iter 780 value 1.867097\n",
      "iter 790 value 1.805308\n",
      "iter 800 value 1.678407\n",
      "iter 810 value 1.173854\n",
      "iter 820 value 0.574697\n",
      "iter 830 value 0.430999\n",
      "iter 840 value 0.166744\n",
      "iter 850 value 0.063296\n",
      "iter 860 value 0.035291\n",
      "iter 870 value 0.025552\n",
      "iter 880 value 0.016830\n",
      "iter 890 value 0.013100\n",
      "iter 900 value 0.010607\n",
      "iter 910 value 0.009049\n",
      "iter 920 value 0.007812\n",
      "iter 930 value 0.006581\n",
      "iter 940 value 0.005783\n",
      "iter 950 value 0.004988\n",
      "iter 960 value 0.004726\n",
      "iter 970 value 0.004432\n",
      "iter 980 value 0.004135\n",
      "iter 990 value 0.003962\n",
      "iter1000 value 0.003707\n",
      "iter1010 value 0.003389\n",
      "iter1020 value 0.003202\n",
      "iter1030 value 0.003008\n",
      "iter1040 value 0.002764\n",
      "iter1050 value 0.002677\n",
      "iter1060 value 0.002570\n",
      "iter1070 value 0.002497\n",
      "iter1080 value 0.002451\n",
      "iter1090 value 0.002451\n",
      "iter1100 value 0.002357\n",
      "iter1110 value 0.002280\n",
      "iter1120 value 0.002159\n",
      "iter1130 value 0.002081\n",
      "iter1140 value 0.001983\n",
      "iter1150 value 0.001922\n",
      "iter1160 value 0.001789\n",
      "iter1170 value 0.001763\n",
      "iter1180 value 0.001682\n",
      "iter1190 value 0.001576\n",
      "iter1200 value 0.001539\n",
      "iter1210 value 0.001487\n",
      "iter1220 value 0.001409\n",
      "iter1230 value 0.001340\n",
      "iter1240 value 0.001311\n",
      "iter1250 value 0.001311\n",
      "iter1260 value 0.001303\n",
      "iter1270 value 0.001285\n",
      "iter1280 value 0.001274\n",
      "iter1290 value 0.001266\n",
      "iter1300 value 0.001266\n",
      "final  value 0.001264 \n",
      "converged\n",
      "[1] \"[INFO] - Misclassification rate - 2 fold: 0.0908300738809213\"\n",
      "[1] \"[INFO] - CV - Mean misclassification rate: 0.104057375229479\"\n",
      "# weights:  2951\n",
      "initial  value 1629.413848 \n",
      "iter  10 value 1363.149430\n",
      "iter  20 value 1329.382222\n",
      "iter  30 value 1268.101132\n",
      "iter  40 value 1172.760856\n",
      "iter  50 value 694.662481\n",
      "iter  60 value 510.040282\n",
      "iter  70 value 432.816117\n",
      "iter  80 value 414.852690\n",
      "iter  90 value 403.221095\n",
      "iter 100 value 398.554753\n",
      "iter 110 value 390.602953\n",
      "iter 120 value 351.682713\n",
      "iter 130 value 278.701410\n",
      "iter 140 value 228.638313\n",
      "iter 150 value 173.609489\n",
      "iter 160 value 120.615239\n",
      "iter 170 value 91.063051\n",
      "iter 180 value 63.227495\n",
      "iter 190 value 44.120191\n",
      "iter 200 value 32.807906\n",
      "iter 210 value 26.582372\n",
      "iter 220 value 24.315245\n",
      "iter 230 value 22.470767\n",
      "iter 240 value 21.088410\n",
      "iter 250 value 20.231324\n",
      "iter 260 value 19.948278\n",
      "iter 270 value 19.758198\n",
      "iter 280 value 19.597224\n",
      "iter 290 value 19.333683\n",
      "iter 300 value 19.173818\n",
      "iter 310 value 19.124235\n",
      "iter 320 value 19.090400\n",
      "iter 330 value 19.076703\n",
      "iter 340 value 19.067689\n",
      "iter 350 value 19.038588\n",
      "iter 360 value 19.030168\n",
      "iter 370 value 19.023421\n",
      "iter 380 value 19.013471\n",
      "iter 390 value 19.003908\n",
      "iter 400 value 18.993842\n",
      "iter 410 value 18.989991\n",
      "iter 420 value 18.988986\n",
      "iter 430 value 18.988325\n",
      "iter 440 value 18.987179\n",
      "iter 450 value 18.979817\n",
      "iter 460 value 18.934404\n",
      "iter 470 value 18.897860\n",
      "iter 480 value 18.638697\n",
      "iter 490 value 18.484113\n",
      "iter 500 value 18.439159\n",
      "iter 510 value 18.407084\n",
      "iter 520 value 18.109041\n",
      "iter 530 value 17.622789\n",
      "iter 540 value 17.415939\n",
      "iter 550 value 17.264874\n",
      "iter 560 value 17.140183\n",
      "iter 570 value 17.018147\n",
      "iter 580 value 16.923491\n",
      "iter 590 value 16.880051\n",
      "iter 600 value 16.864499\n",
      "iter 610 value 16.857350\n",
      "iter 620 value 16.855509\n",
      "iter 630 value 16.855092\n",
      "iter 640 value 16.854751\n",
      "iter 650 value 16.854486\n",
      "iter 660 value 16.854339\n",
      "iter 670 value 16.854067\n",
      "iter 680 value 16.853953\n",
      "iter 690 value 16.853828\n",
      "iter 700 value 16.853816\n",
      "iter 700 value 16.853816\n",
      "iter 700 value 16.853816\n",
      "final  value 16.853816 \n",
      "converged\n",
      "[1] \"[INFO] - Confusion matrix In sample :\"\n",
      "       \n",
      "Y_hat   FALSE TRUE\n",
      "  FALSE  1419    1\n",
      "  TRUE      4  876\n",
      "[1] \"[INFO] - Misclassification rate In sample : 0.00217391304347825\"\n",
      "[1] \"[INFO] - Confusion matrix Out sample :\"\n",
      "       \n",
      "Y_hat   FALSE TRUE\n",
      "  FALSE  1257   84\n",
      "  TRUE    108  852\n",
      "[1] \"[INFO] - Misclassification rate Out sample : 0.0834419817470665\"\n",
      "[1] \"[INFO] - Training set size: 2301 - Testing set size 2300\"\n",
      "# weights:  5901\n",
      "initial  value 1645.047728 \n",
      "iter  10 value 1296.685059\n",
      "iter  20 value 1243.055161\n",
      "iter  30 value 1175.571062\n",
      "iter  40 value 1054.709471\n",
      "iter  50 value 860.275297\n",
      "iter  60 value 732.220532\n",
      "iter  70 value 680.506782\n",
      "iter  80 value 622.268927\n",
      "iter  90 value 582.178381\n",
      "iter 100 value 553.075364\n",
      "iter 110 value 539.243846\n",
      "iter 120 value 457.918231\n",
      "iter 130 value 402.372402\n",
      "iter 140 value 375.440369\n",
      "iter 150 value 321.262802\n",
      "iter 160 value 304.406494\n",
      "iter 170 value 300.715978\n",
      "iter 180 value 289.477946\n",
      "iter 190 value 277.544985\n",
      "iter 200 value 261.235727\n",
      "iter 210 value 243.562849\n",
      "iter 220 value 193.475586\n",
      "iter 230 value 155.256374\n",
      "iter 240 value 124.180342\n",
      "iter 250 value 97.473730\n",
      "iter 260 value 77.934063\n",
      "iter 270 value 73.746106\n",
      "iter 280 value 70.927406\n",
      "iter 290 value 63.453572\n",
      "iter 300 value 55.682160\n",
      "iter 310 value 50.713955\n",
      "iter 320 value 49.792850\n",
      "iter 330 value 48.960718\n",
      "iter 340 value 46.987657\n",
      "iter 350 value 46.514446\n",
      "iter 360 value 46.205440\n",
      "iter 370 value 45.721290\n",
      "iter 380 value 42.419082\n",
      "iter 390 value 35.803902\n",
      "iter 400 value 29.045631\n",
      "iter 410 value 16.798348\n",
      "iter 420 value 8.356136\n",
      "iter 430 value 2.485549\n",
      "iter 440 value 0.541268\n",
      "iter 450 value 0.060613\n",
      "iter 460 value 0.013316\n",
      "iter 470 value 0.004763\n",
      "iter 480 value 0.002348\n",
      "iter 490 value 0.001053\n",
      "iter 500 value 0.000725\n",
      "iter 510 value 0.000462\n",
      "iter 520 value 0.000336\n",
      "iter 530 value 0.000247\n",
      "iter 540 value 0.000145\n",
      "iter 550 value 0.000119\n",
      "final  value 0.000097 \n",
      "converged\n",
      "[1] \"[INFO] - Misclassification rate - 1 fold: 0.0795652173913044\"\n",
      "[1] \"[INFO] - Training set size: 2300 - Testing set size 2301\"\n",
      "# weights:  5901\n",
      "initial  value 1525.735309 \n",
      "iter  10 value 1297.254164\n",
      "iter  20 value 1267.238886\n",
      "iter  30 value 1180.970594\n",
      "iter  40 value 1078.408754\n",
      "iter  50 value 944.567956\n",
      "iter  60 value 898.516461\n",
      "iter  70 value 794.372214\n",
      "iter  80 value 748.024449\n",
      "iter  90 value 630.747339\n",
      "iter 100 value 533.545076\n",
      "iter 110 value 476.378471\n",
      "iter 120 value 463.538781\n",
      "iter 130 value 431.819853\n",
      "iter 140 value 399.914725\n",
      "iter 150 value 357.728681\n",
      "iter 160 value 320.896151\n",
      "iter 170 value 294.945565\n",
      "iter 180 value 256.003053\n",
      "iter 190 value 224.278538\n",
      "iter 200 value 186.571024\n",
      "iter 210 value 139.170512\n",
      "iter 220 value 99.315314\n",
      "iter 230 value 74.735493\n",
      "iter 240 value 36.666919\n",
      "iter 250 value 26.841865\n",
      "iter 260 value 10.102284\n",
      "iter 270 value 3.737337\n",
      "iter 280 value 0.324792\n",
      "iter 290 value 0.021069\n",
      "iter 300 value 0.004229\n",
      "iter 310 value 0.001279\n",
      "iter 320 value 0.000542\n",
      "iter 330 value 0.000260\n",
      "iter 340 value 0.000119\n",
      "final  value 0.000090 \n",
      "converged\n",
      "[1] \"[INFO] - Misclassification rate - 2 fold: 0.0777922642329422\"\n",
      "[1] \"[INFO] - CV - Mean misclassification rate: 0.102623159482072\"\n",
      "# weights:  5901\n",
      "initial  value 1717.513007 \n",
      "iter  10 value 1318.561759\n",
      "iter  20 value 1239.133153\n",
      "iter  30 value 1152.905474\n",
      "iter  40 value 962.611164\n",
      "iter  50 value 678.176477\n",
      "iter  60 value 489.774901\n",
      "iter  70 value 456.954884\n",
      "iter  80 value 402.532322\n",
      "iter  90 value 352.773420\n",
      "iter 100 value 335.564679\n",
      "iter 110 value 326.039038\n",
      "iter 120 value 296.468332\n",
      "iter 130 value 267.011162\n",
      "iter 140 value 247.623611\n",
      "iter 150 value 240.868845\n",
      "iter 160 value 226.585051\n",
      "iter 170 value 209.320059\n",
      "iter 180 value 187.208179\n",
      "iter 190 value 132.930130\n",
      "iter 200 value 110.023928\n",
      "iter 210 value 107.986273\n",
      "iter 220 value 106.679875\n",
      "iter 230 value 106.110873\n",
      "iter 240 value 105.320014\n",
      "iter 250 value 103.458343\n",
      "iter 260 value 102.665399\n",
      "iter 270 value 101.221969\n",
      "iter 280 value 97.374657\n",
      "iter 290 value 87.541260\n",
      "iter 300 value 71.123732\n",
      "iter 310 value 53.028067\n",
      "iter 320 value 30.699565\n",
      "iter 330 value 19.677811\n",
      "iter 340 value 15.180900\n",
      "iter 350 value 14.502063\n",
      "iter 360 value 13.956561\n",
      "iter 370 value 13.557004\n",
      "iter 380 value 12.430130\n",
      "iter 390 value 11.000475\n",
      "iter 400 value 8.767010\n",
      "iter 410 value 7.363183\n",
      "iter 420 value 5.817053\n",
      "iter 430 value 3.511922\n",
      "iter 440 value 2.341511\n",
      "iter 450 value 1.582386\n",
      "iter 460 value 1.458069\n",
      "iter 470 value 1.411336\n",
      "iter 480 value 1.370154\n",
      "iter 490 value 1.297149\n",
      "iter 500 value 1.212934\n",
      "iter 510 value 1.067240\n",
      "iter 520 value 0.918771\n",
      "iter 530 value 0.678253\n",
      "iter 540 value 0.464079\n",
      "iter 550 value 0.148274\n",
      "iter 560 value 0.062338\n",
      "iter 570 value 0.033086\n",
      "iter 580 value 0.023529\n",
      "iter 590 value 0.017819\n",
      "iter 600 value 0.013788\n",
      "iter 610 value 0.011422\n",
      "iter 620 value 0.009435\n",
      "iter 630 value 0.007738\n",
      "iter 640 value 0.006657\n",
      "iter 650 value 0.005761\n",
      "iter 660 value 0.005057\n",
      "iter 670 value 0.004354\n",
      "iter 680 value 0.003790\n",
      "iter 690 value 0.003108\n",
      "iter 700 value 0.002570\n",
      "iter 710 value 0.002083\n",
      "iter 720 value 0.001667\n",
      "iter 730 value 0.001378\n",
      "iter 740 value 0.001224\n",
      "iter 750 value 0.001016\n",
      "iter 760 value 0.000928\n",
      "iter 770 value 0.000796\n",
      "iter 780 value 0.000699\n",
      "iter 790 value 0.000603\n",
      "iter 800 value 0.000509\n",
      "iter 810 value 0.000464\n",
      "iter 820 value 0.000422\n",
      "iter 830 value 0.000389\n",
      "iter 840 value 0.000365\n",
      "iter 850 value 0.000326\n",
      "iter 860 value 0.000297\n",
      "iter 870 value 0.000270\n",
      "iter 880 value 0.000243\n",
      "iter 890 value 0.000229\n",
      "iter 900 value 0.000203\n",
      "iter 910 value 0.000197\n",
      "iter 920 value 0.000183\n",
      "iter 930 value 0.000172\n",
      "iter 940 value 0.000150\n",
      "iter 950 value 0.000122\n",
      "iter 960 value 0.000114\n",
      "iter 970 value 0.000114\n",
      "iter 980 value 0.000113\n",
      "iter 990 value 0.000113\n",
      "iter1000 value 0.000113\n",
      "final  value 0.000113 \n",
      "converged\n",
      "[1] \"[INFO] - Confusion matrix In sample :\"\n",
      "       \n",
      "Y_hat   FALSE TRUE\n",
      "  FALSE  1413    0\n",
      "  TRUE      0  887\n",
      "[1] \"[INFO] - Misclassification rate In sample : 0\"\n",
      "[1] \"[INFO] - Confusion matrix Out sample :\"\n",
      "       \n",
      "Y_hat   FALSE TRUE\n",
      "  FALSE  1287   85\n",
      "  TRUE     88  841\n",
      "[1] \"[INFO] - Misclassification rate Out sample : 0.0751847023033464\"\n"
     ]
    }
   ],
   "source": [
    "k <- 2\n",
    "hidden_nodes_vec <- c(3,5,10,15,30,50,100)\n",
    "\n",
    "error_in_sample_vec <- numeric()\n",
    "error_out_sample_vec <- numeric()\n",
    "error_cv_vec <- numeric()\n",
    "\n",
    "for(hidden_nodes in hidden_nodes_vec){\n",
    "    results <- crossValidationInOutSample(hidden_nodes=hidden_nodes,k=k)\n",
    "    error_in_sample_vec <- cbind(error_in_sample_vec,results$in_sample)\n",
    "    error_out_sample_vec <- cbind(error_out_sample_vec,results$out_sample)\n",
    "    error_cv_vec <- cbind(error_cv_vec,results$cv)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAAAP9NTU1oaGh8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\nQgIECAkQICRAgJAAAUICBAgJECAkQOB/6JdIQMn2paEAAAAASUVORK5CYII=",
      "text/plain": [
       "Plot with title \"NN accuracy as a function of neurons\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(hidden_nodes_vec,error_in_sample_vec,type=\"n\",main=\"NN accuracy as a function of neurons\",xlab=\"Hidden neurons\",ylab=\"Accuracy\",ylim=c(0.85,1))\n",
    "lines(hidden_nodes_vec,error_in_sample_vec)\n",
    "lines(hidden_nodes_vec,error_out_sample_vec,col=\"blue\")\n",
    "lines(hidden_nodes_vec,error_cv_vec,col=\"red\")\n",
    "legend(\"bottomright\",legend=c(\"In sample\",\"Out of sample\",\"CV\"),col=c(\"black\",\"blue\",\"red\"),lty=c(1,1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Neural Networks\n",
    "\n",
    "Given a standard training set $D$ of size $n$, bagging generates $m$ new training sets $D_i$, each of size $n′$, by sampling from $D$ uniformly and with replacement. By sampling with replacement, some observations may be repeated in each $D_{i}$\n",
    "Bagging leads to \"improvements for unstable procedures\" (Breiman, 1996), which include, for example, artificial neural networks, classification and regression trees. On the other hand, it can mildly degrade the performance of stable methods such as K-nearest neighbors (Breiman, 1996).\n",
    "\n",
    "We would like to study the impact of bagging on the problem at hand.\n",
    "In order to do so you have to:\n",
    "\n",
    "- Develop a basic (50/50 split) neural network model\n",
    "- Develop a bagged version of the same model\n",
    "- Compare (through tables and/or plots) the perfomances of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a 57-5-1 network with 296 weights\n",
       "inputs: word_freq_make word_freq_address word_freq_all word_freq_3d word_freq_our word_freq_over word_freq_remove word_freq_internet word_freq_order word_freq_mail word_freq_receive word_freq_will word_freq_people word_freq_report word_freq_addresses word_freq_free word_freq_business word_freq_email word_freq_you word_freq_credit word_freq_your word_freq_font word_freq_000 word_freq_money word_freq_hp word_freq_hpl word_freq_george word_freq_650 word_freq_lab word_freq_labs word_freq_telnet word_freq_857 word_freq_data word_freq_415 word_freq_85 word_freq_technology word_freq_1999 word_freq_parts word_freq_pm word_freq_direct word_freq_cs word_freq_meeting word_freq_original word_freq_project word_freq_re word_freq_edu word_freq_table word_freq_conference char_freq_semicolon char_freq_left_paren char_freq_left_bracket char_freq_exclamation char_freq_dollar char_freq_pound capital_run_length_average capital_run_length_longest capital_run_length_total \n",
       "output(s): is_spam \n",
       "options were - entropy fitting "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"[INFO] - Confusion matrix single model :\"\n",
      "       \n",
      "Y_hat   FALSE TRUE\n",
      "  FALSE  1326   69\n",
      "  TRUE     66  840\n",
      "[1] \"[INFO] - Misclassification rate single model : 0.0586701434159062\"\n"
     ]
    }
   ],
   "source": [
    "hidden_nodes <- 5\n",
    "\n",
    "set.seed(1000)\n",
    "model <- nnet(is_spam ~ ., data=train_data,size=hidden_nodes,skip=FALSE, maxit=3000,rang=0.2,MaxNWts=10000,trace=FALSE)\n",
    "model\n",
    "\n",
    "# 4.2 - In sample evaluation error computation\n",
    "Y_pred<-predict(model,test_data[,-target_variable])\n",
    "Y_hat <- Y_pred > threshold\n",
    "\n",
    "accuracy <- displayResults(Y,Y_hat,\"single model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"[INFO] - Confusion matrix 1 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1008  119\n",
      "    1   384  790\n",
      "[1] \"[INFO] - Misclassification rate 1 th model : 0.218600608431117\"\n",
      "[1] \"[INFO] - Confusion matrix 2 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1243  218\n",
      "    1   149  691\n",
      "[1] \"[INFO] - Misclassification rate 2 th model : 0.159495871360278\"\n",
      "[1] \"[INFO] - Confusion matrix 3 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1117  288\n",
      "    1   275  621\n",
      "[1] \"[INFO] - Misclassification rate 3 th model : 0.244676227727075\"\n",
      "[1] \"[INFO] - Confusion matrix 4 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1040  182\n",
      "    1   352  727\n",
      "[1] \"[INFO] - Misclassification rate 4 th model : 0.232073011734029\"\n",
      "[1] \"[INFO] - Confusion matrix 5 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1088  204\n",
      "    1   304  705\n",
      "[1] \"[INFO] - Misclassification rate 5 th model : 0.22077357670578\"\n",
      "[1] \"[INFO] - Confusion matrix 6 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0   746  237\n",
      "    1   646  672\n",
      "[1] \"[INFO] - Misclassification rate 6 th model : 0.383746197305519\"\n",
      "[1] \"[INFO] - Confusion matrix 7 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1226  407\n",
      "    1   166  502\n",
      "[1] \"[INFO] - Misclassification rate 7 th model : 0.249022164276402\"\n",
      "[1] \"[INFO] - Confusion matrix 8 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1140  160\n",
      "    1   252  749\n",
      "[1] \"[INFO] - Misclassification rate 8 th model : 0.179052585832247\"\n",
      "[1] \"[INFO] - Confusion matrix 9 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1251  396\n",
      "    1   141  513\n",
      "[1] \"[INFO] - Misclassification rate 9 th model : 0.233376792698827\"\n",
      "[1] \"[INFO] - Confusion matrix 10 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1001  111\n",
      "    1   391  798\n",
      "[1] \"[INFO] - Misclassification rate 10 th model : 0.218166014776184\"\n",
      "[1] \"[INFO] - Confusion matrix 11 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1169   79\n",
      "    1   223  830\n",
      "[1] \"[INFO] - Misclassification rate 11 th model : 0.131247283789657\"\n",
      "[1] \"[INFO] - Confusion matrix 12 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1088  182\n",
      "    1   304  727\n",
      "[1] \"[INFO] - Misclassification rate 12 th model : 0.211212516297262\"\n",
      "[1] \"[INFO] - Confusion matrix 13 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1118  161\n",
      "    1   274  748\n",
      "[1] \"[INFO] - Misclassification rate 13 th model : 0.189048239895698\"\n",
      "[1] \"[INFO] - Confusion matrix 14 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1000  107\n",
      "    1   392  802\n",
      "[1] \"[INFO] - Misclassification rate 14 th model : 0.216862233811386\"\n",
      "[1] \"[INFO] - Confusion matrix 15 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1050  191\n",
      "    1   342  718\n",
      "[1] \"[INFO] - Misclassification rate 15 th model : 0.231638418079096\"\n",
      "[1] \"[INFO] - Confusion matrix 16 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0   996  301\n",
      "    1   396  608\n",
      "[1] \"[INFO] - Misclassification rate 16 th model : 0.302911777488049\"\n",
      "[1] \"[INFO] - Confusion matrix 17 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1175  170\n",
      "    1   217  739\n",
      "[1] \"[INFO] - Misclassification rate 17 th model : 0.168187744458931\"\n",
      "[1] \"[INFO] - Confusion matrix 18 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0   984  192\n",
      "    1   408  717\n",
      "[1] \"[INFO] - Misclassification rate 18 th model : 0.260756192959583\"\n",
      "[1] \"[INFO] - Confusion matrix 19 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1249  205\n",
      "    1   143  704\n",
      "[1] \"[INFO] - Misclassification rate 19 th model : 0.151238591916558\"\n",
      "[1] \"[INFO] - Confusion matrix 20 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1222  189\n",
      "    1   170  720\n",
      "[1] \"[INFO] - Misclassification rate 20 th model : 0.156019122120817\"\n",
      "[1] \"[INFO] - Confusion matrix 21 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1185  246\n",
      "    1   207  663\n",
      "[1] \"[INFO] - Misclassification rate 21 th model : 0.196870925684485\"\n",
      "[1] \"[INFO] - Confusion matrix 22 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1261  326\n",
      "    1   131  583\n",
      "[1] \"[INFO] - Misclassification rate 22 th model : 0.198609300304216\"\n",
      "[1] \"[INFO] - Confusion matrix 23 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1184  212\n",
      "    1   208  697\n",
      "[1] \"[INFO] - Misclassification rate 23 th model : 0.182529335071708\"\n",
      "[1] \"[INFO] - Confusion matrix 24 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0   961  319\n",
      "    1   431  590\n",
      "[1] \"[INFO] - Misclassification rate 24 th model : 0.325945241199479\"\n",
      "[1] \"[INFO] - Confusion matrix 25 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1076  339\n",
      "    1   316  570\n",
      "[1] \"[INFO] - Misclassification rate 25 th model : 0.284658843980878\"\n",
      "[1] \"[INFO] - Confusion matrix 26 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1191  268\n",
      "    1   201  641\n",
      "[1] \"[INFO] - Misclassification rate 26 th model : 0.203824424163407\"\n",
      "[1] \"[INFO] - Confusion matrix 27 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1188  289\n",
      "    1   204  620\n",
      "[1] \"[INFO] - Misclassification rate 27 th model : 0.21425467188179\"\n",
      "[1] \"[INFO] - Confusion matrix 28 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1146  213\n",
      "    1   246  696\n",
      "[1] \"[INFO] - Misclassification rate 28 th model : 0.199478487614081\"\n",
      "[1] \"[INFO] - Confusion matrix 29 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0   953  138\n",
      "    1   439  771\n",
      "[1] \"[INFO] - Misclassification rate 29 th model : 0.250760538896132\"\n",
      "[1] \"[INFO] - Confusion matrix 30 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1219  263\n",
      "    1   173  646\n",
      "[1] \"[INFO] - Misclassification rate 30 th model : 0.18948283355063\"\n",
      "[1] \"[INFO] - Confusion matrix 31 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0   697   36\n",
      "    1   695  873\n",
      "[1] \"[INFO] - Misclassification rate 31 th model : 0.317687961755758\"\n",
      "[1] \"[INFO] - Confusion matrix 32 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0   842  262\n",
      "    1   550  647\n",
      "[1] \"[INFO] - Misclassification rate 32 th model : 0.352890047805302\"\n",
      "[1] \"[INFO] - Confusion matrix 33 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1147  380\n",
      "    1   245  529\n",
      "[1] \"[INFO] - Misclassification rate 33 th model : 0.271621034332899\"\n",
      "[1] \"[INFO] - Confusion matrix 34 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0   998  127\n",
      "    1   394  782\n",
      "[1] \"[INFO] - Misclassification rate 34 th model : 0.226423294219904\"\n",
      "[1] \"[INFO] - Confusion matrix 35 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1079  231\n",
      "    1   313  678\n",
      "[1] \"[INFO] - Misclassification rate 35 th model : 0.236418948283355\"\n",
      "[1] \"[INFO] - Confusion matrix 36 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1177  239\n",
      "    1   215  670\n",
      "[1] \"[INFO] - Misclassification rate 36 th model : 0.197305519339418\"\n",
      "[1] \"[INFO] - Confusion matrix 37 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1059  172\n",
      "    1   333  737\n",
      "[1] \"[INFO] - Misclassification rate 37 th model : 0.219469795740982\"\n",
      "[1] \"[INFO] - Confusion matrix 38 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1042  150\n",
      "    1   350  759\n",
      "[1] \"[INFO] - Misclassification rate 38 th model : 0.217296827466319\"\n",
      "[1] \"[INFO] - Confusion matrix 39 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0   713   57\n",
      "    1   679  852\n",
      "[1] \"[INFO] - Misclassification rate 39 th model : 0.319860930030422\"\n",
      "[1] \"[INFO] - Confusion matrix 40 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0   954   98\n",
      "    1   438  811\n",
      "[1] \"[INFO] - Misclassification rate 40 th model : 0.232942199043894\"\n",
      "[1] \"[INFO] - Confusion matrix 41 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1211  203\n",
      "    1   181  706\n",
      "[1] \"[INFO] - Misclassification rate 41 th model : 0.166883963494133\"\n",
      "[1] \"[INFO] - Confusion matrix 42 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1069  160\n",
      "    1   323  749\n",
      "[1] \"[INFO] - Misclassification rate 42 th model : 0.209908735332464\"\n",
      "[1] \"[INFO] - Confusion matrix 43 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1086  255\n",
      "    1   306  654\n",
      "[1] \"[INFO] - Misclassification rate 43 th model : 0.24380704041721\"\n",
      "[1] \"[INFO] - Confusion matrix 44 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1244  321\n",
      "    1   148  588\n",
      "[1] \"[INFO] - Misclassification rate 44 th model : 0.203824424163407\"\n",
      "[1] \"[INFO] - Confusion matrix 45 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1029  124\n",
      "    1   363  785\n",
      "[1] \"[INFO] - Misclassification rate 45 th model : 0.211647109952195\"\n",
      "[1] \"[INFO] - Confusion matrix 46 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1099  169\n",
      "    1   293  740\n",
      "[1] \"[INFO] - Misclassification rate 46 th model : 0.200782268578879\"\n",
      "[1] \"[INFO] - Confusion matrix 47 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1241  188\n",
      "    1   151  721\n",
      "[1] \"[INFO] - Misclassification rate 47 th model : 0.147327249022164\"\n",
      "[1] \"[INFO] - Confusion matrix 48 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1268  166\n",
      "    1   124  743\n",
      "[1] \"[INFO] - Misclassification rate 48 th model : 0.126032159930465\"\n",
      "[1] \"[INFO] - Confusion matrix 49 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0   898  439\n",
      "    1   494  470\n",
      "[1] \"[INFO] - Misclassification rate 49 th model : 0.405475880052151\"\n",
      "[1] \"[INFO] - Confusion matrix 50 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0   988  111\n",
      "    1   404  798\n",
      "[1] \"[INFO] - Misclassification rate 50 th model : 0.223815732290309\"\n",
      "[1] \"[INFO] - Confusion matrix 51 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1041  111\n",
      "    1   351  798\n",
      "[1] \"[INFO] - Misclassification rate 51 th model : 0.200782268578879\"\n",
      "[1] \"[INFO] - Confusion matrix 52 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1050  164\n",
      "    1   342  745\n",
      "[1] \"[INFO] - Misclassification rate 52 th model : 0.219904389395915\"\n",
      "[1] \"[INFO] - Confusion matrix 53 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0   800  167\n",
      "    1   592  742\n",
      "[1] \"[INFO] - Misclassification rate 53 th model : 0.329856584093872\"\n",
      "[1] \"[INFO] - Confusion matrix 54 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1012  136\n",
      "    1   380  773\n",
      "[1] \"[INFO] - Misclassification rate 54 th model : 0.224250325945241\"\n",
      "[1] \"[INFO] - Confusion matrix 55 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1207  179\n",
      "    1   185  730\n",
      "[1] \"[INFO] - Misclassification rate 55 th model : 0.15819209039548\"\n",
      "[1] \"[INFO] - Confusion matrix 56 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0   860  174\n",
      "    1   532  735\n",
      "[1] \"[INFO] - Misclassification rate 56 th model : 0.306823120382442\"\n",
      "[1] \"[INFO] - Confusion matrix 57 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1132  202\n",
      "    1   260  707\n",
      "[1] \"[INFO] - Misclassification rate 57 th model : 0.200782268578879\"\n",
      "[1] \"[INFO] - Confusion matrix 58 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1079  219\n",
      "    1   313  690\n",
      "[1] \"[INFO] - Misclassification rate 58 th model : 0.231203824424163\"\n",
      "[1] \"[INFO] - Confusion matrix 59 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0   418   25\n",
      "    1   974  884\n",
      "[1] \"[INFO] - Misclassification rate 59 th model : 0.434159061277705\"\n",
      "[1] \"[INFO] - Confusion matrix 60 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1240  357\n",
      "    1   152  552\n",
      "[1] \"[INFO] - Misclassification rate 60 th model : 0.221208170360713\"\n",
      "[1] \"[INFO] - Confusion matrix 61 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1115  200\n",
      "    1   277  709\n",
      "[1] \"[INFO] - Misclassification rate 61 th model : 0.207301173402868\"\n",
      "[1] \"[INFO] - Confusion matrix 62 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1224  219\n",
      "    1   168  690\n",
      "[1] \"[INFO] - Misclassification rate 62 th model : 0.168187744458931\"\n",
      "[1] \"[INFO] - Confusion matrix 63 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0   870  198\n",
      "    1   522  711\n",
      "[1] \"[INFO] - Misclassification rate 63 th model : 0.312907431551499\"\n",
      "[1] \"[INFO] - Confusion matrix 64 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1073   75\n",
      "    1   319  834\n",
      "[1] \"[INFO] - Misclassification rate 64 th model : 0.171229900043459\"\n",
      "[1] \"[INFO] - Confusion matrix 65 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1216  207\n",
      "    1   176  702\n",
      "[1] \"[INFO] - Misclassification rate 65 th model : 0.1664493698392\"\n",
      "[1] \"[INFO] - Confusion matrix 66 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1079  199\n",
      "    1   313  710\n",
      "[1] \"[INFO] - Misclassification rate 66 th model : 0.222511951325511\"\n",
      "[1] \"[INFO] - Confusion matrix 67 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0   965  104\n",
      "    1   427  805\n",
      "[1] \"[INFO] - Misclassification rate 67 th model : 0.230769230769231\"\n",
      "[1] \"[INFO] - Confusion matrix 68 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1126  457\n",
      "    1   266  452\n",
      "[1] \"[INFO] - Misclassification rate 68 th model : 0.314211212516297\"\n",
      "[1] \"[INFO] - Confusion matrix 69 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1157  309\n",
      "    1   235  600\n",
      "[1] \"[INFO] - Misclassification rate 69 th model : 0.236418948283355\"\n",
      "[1] \"[INFO] - Confusion matrix 70 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0   826  110\n",
      "    1   566  799\n",
      "[1] \"[INFO] - Misclassification rate 70 th model : 0.293785310734463\"\n",
      "[1] \"[INFO] - Confusion matrix 71 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1187  296\n",
      "    1   205  613\n",
      "[1] \"[INFO] - Misclassification rate 71 th model : 0.217731421121252\"\n",
      "[1] \"[INFO] - Confusion matrix 72 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1062  120\n",
      "    1   330  789\n",
      "[1] \"[INFO] - Misclassification rate 72 th model : 0.195567144719687\"\n",
      "[1] \"[INFO] - Confusion matrix 73 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1205  106\n",
      "    1   187  803\n",
      "[1] \"[INFO] - Misclassification rate 73 th model : 0.127335940895263\"\n",
      "[1] \"[INFO] - Confusion matrix 74 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1251  600\n",
      "    1   141  309\n",
      "[1] \"[INFO] - Misclassification rate 74 th model : 0.322033898305085\"\n",
      "[1] \"[INFO] - Confusion matrix 75 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1320  317\n",
      "    1    72  592\n",
      "[1] \"[INFO] - Misclassification rate 75 th model : 0.169056931768796\"\n",
      "[1] \"[INFO] - Confusion matrix 76 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1041  296\n",
      "    1   351  613\n",
      "[1] \"[INFO] - Misclassification rate 76 th model : 0.281182094741417\"\n",
      "[1] \"[INFO] - Confusion matrix 77 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1129  114\n",
      "    1   263  795\n",
      "[1] \"[INFO] - Misclassification rate 77 th model : 0.163841807909605\"\n",
      "[1] \"[INFO] - Confusion matrix 78 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1030  182\n",
      "    1   362  727\n",
      "[1] \"[INFO] - Misclassification rate 78 th model : 0.236418948283355\"\n",
      "[1] \"[INFO] - Confusion matrix 79 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1334  725\n",
      "    1    58  184\n",
      "[1] \"[INFO] - Misclassification rate 79 th model : 0.340286831812255\"\n",
      "[1] \"[INFO] - Confusion matrix 80 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1219  210\n",
      "    1   173  699\n",
      "[1] \"[INFO] - Misclassification rate 80 th model : 0.1664493698392\"\n",
      "[1] \"[INFO] - Confusion matrix 81 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1197  208\n",
      "    1   195  701\n",
      "[1] \"[INFO] - Misclassification rate 81 th model : 0.175141242937853\"\n",
      "[1] \"[INFO] - Confusion matrix 82 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1097  202\n",
      "    1   295  707\n",
      "[1] \"[INFO] - Misclassification rate 82 th model : 0.215993046501521\"\n",
      "[1] \"[INFO] - Confusion matrix 83 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1325  420\n",
      "    1    67  489\n",
      "[1] \"[INFO] - Misclassification rate 83 th model : 0.211647109952195\"\n",
      "[1] \"[INFO] - Confusion matrix 84 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1232  458\n",
      "    1   160  451\n",
      "[1] \"[INFO] - Misclassification rate 84 th model : 0.26857887874837\"\n",
      "[1] \"[INFO] - Confusion matrix 85 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1277  394\n",
      "    1   115  515\n",
      "[1] \"[INFO] - Misclassification rate 85 th model : 0.221208170360713\"\n",
      "[1] \"[INFO] - Confusion matrix 86 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1175  647\n",
      "    1   217  262\n",
      "[1] \"[INFO] - Misclassification rate 86 th model : 0.375488917861799\"\n",
      "[1] \"[INFO] - Confusion matrix 87 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1238  282\n",
      "    1   154  627\n",
      "[1] \"[INFO] - Misclassification rate 87 th model : 0.18948283355063\"\n",
      "[1] \"[INFO] - Confusion matrix 88 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1282  324\n",
      "    1   110  585\n",
      "[1] \"[INFO] - Misclassification rate 88 th model : 0.188613646240765\"\n",
      "[1] \"[INFO] - Confusion matrix 89 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1163  200\n",
      "    1   229  709\n",
      "[1] \"[INFO] - Misclassification rate 89 th model : 0.186440677966102\"\n",
      "[1] \"[INFO] - Confusion matrix 90 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1149  229\n",
      "    1   243  680\n",
      "[1] \"[INFO] - Misclassification rate 90 th model : 0.205128205128205\"\n",
      "[1] \"[INFO] - Confusion matrix 91 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1226  349\n",
      "    1   166  560\n",
      "[1] \"[INFO] - Misclassification rate 91 th model : 0.223815732290309\"\n",
      "[1] \"[INFO] - Confusion matrix 92 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1374  906\n",
      "    1    18    3\n",
      "[1] \"[INFO] - Misclassification rate 92 th model : 0.401564537157758\"\n",
      "[1] \"[INFO] - Confusion matrix 93 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1186  393\n",
      "    1   206  516\n",
      "[1] \"[INFO] - Misclassification rate 93 th model : 0.26032159930465\"\n",
      "[1] \"[INFO] - Confusion matrix 94 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0   883   68\n",
      "    1   509  841\n",
      "[1] \"[INFO] - Misclassification rate 94 th model : 0.250760538896132\"\n",
      "[1] \"[INFO] - Confusion matrix 95 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0   913  198\n",
      "    1   479  711\n",
      "[1] \"[INFO] - Misclassification rate 95 th model : 0.294219904389396\"\n",
      "[1] \"[INFO] - Confusion matrix 96 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0   802  123\n",
      "    1   590  786\n",
      "[1] \"[INFO] - Misclassification rate 96 th model : 0.309865275966971\"\n",
      "[1] \"[INFO] - Confusion matrix 97 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1180  193\n",
      "    1   212  716\n",
      "[1] \"[INFO] - Misclassification rate 97 th model : 0.176010430247718\"\n",
      "[1] \"[INFO] - Confusion matrix 98 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1245  306\n",
      "    1   147  603\n",
      "[1] \"[INFO] - Misclassification rate 98 th model : 0.196870925684485\"\n",
      "[1] \"[INFO] - Confusion matrix 99 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1158  260\n",
      "    1   234  649\n",
      "[1] \"[INFO] - Misclassification rate 99 th model : 0.214689265536723\"\n",
      "[1] \"[INFO] - Confusion matrix 100 th model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1152   69\n",
      "    1   240  840\n",
      "[1] \"[INFO] - Misclassification rate 100 th model : 0.134289439374185\"\n"
     ]
    }
   ],
   "source": [
    "bagging_samples <- 100\n",
    "\n",
    "n_bag <- length(train_data)\n",
    "Y_hat_models<-numeric()\n",
    "Y_hat_bagged<-array(0,c(length(test_data),1))\n",
    "Y <- test_data[,target_variable]\n",
    "accuracy_vec<-array(0,c(1,bagging_samples))\n",
    "\n",
    "for (i in 1:bagging_samples)\n",
    "{\n",
    "  set.seed(1717+i)\n",
    "  # 1. Resample data from the training set\n",
    "  I_bag <- sample(seq(1,n_bag),replace=TRUE)\n",
    "  set.seed(555)\n",
    "  # 2. Fit model\n",
    "  model <- nnet (is_spam ~ .,train_data[I_bag,],skip=FALSE,\n",
    "                   size=hidden_nodes, maxit=10000,trace=F,rang=0.2)\n",
    "  Y_pred <- predict(model,test_data[,-target_variable])\n",
    "  Y_hat_models <- cbind(Y_hat_models,Y_pred > threshold)\n",
    "  accuracy_vec[i] <- displayResults(Y,Y_hat_models[,i],paste(i,\"th model\"))\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"[INFO] - Confusion matrix bagged model :\"\n",
      "     \n",
      "Y_hat FALSE TRUE\n",
      "    0  1237   79\n",
      "    1   155  830\n",
      "[1] \"[INFO] - Misclassification rate bagged model : 0.101694915254237\"\n",
      "[1] \"Average accuracy across the individual models: 0.231069100391134\"\n"
     ]
    }
   ],
   "source": [
    "# 3. Majority vote of the classifiers to make the prediction\n",
    "# Computation trick : With classes being 0/1 if there is a majority of 1 classes, \n",
    "# the sum of all the values should be greater than the number of models/2\n",
    "Y_hat_bagged <- as.numeric(apply(Y_hat_models,1,sum) > (bagging_samples/2))\n",
    "\n",
    "accuracy_bag <- displayResults(Y,Y_hat_bagged,\"bagged model\")\n",
    "\n",
    "print(paste(\"Average misclassification rate across the individual models:\", 1-mean(accuracy_vec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAAAP9NTU1oaGh8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\nAQIICRBASIAAQgIEEBIggJAAAYQECPgfXLlihKEjWaAAAAAASUVORK5CYII=",
      "text/plain": [
       "Plot with title \"Accuracy of models across bagging\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist(accuracy_vec,main='Accuracy of models across bagging',xlab=\"Accuracy\",xlim=c(0,1))\n",
    "abline(v=accuracy_bag,col=\"red\")\n",
    "abline(v=accuracy,col=\"blue\")\n",
    "legend(\"topleft\",legend=c(\"Bagged\",\"Single\"),col=c(\"red\",\"blue\"),lty=c(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus - Caret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'caret' was built under R version 3.4.4\"Loading required package: lattice\n",
      "Warning message:\n",
      "\"package 'lattice' was built under R version 3.4.2\"Loading required package: ggplot2\n",
      "\n",
      "Attaching package: 'caret'\n",
      "\n",
      "The following objects are masked from 'package:RSNNS':\n",
      "\n",
      "    confusionMatrix, train\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>decay</th><th scope=col>size</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0 </td><td> 3</td></tr>\n",
       "\t<tr><td>0 </td><td> 5</td></tr>\n",
       "\t<tr><td>0 </td><td>10</td></tr>\n",
       "\t<tr><td>0 </td><td>15</td></tr>\n",
       "\t<tr><td>0 </td><td>20</td></tr>\n",
       "\t<tr><td>0 </td><td>50</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " decay & size\\\\\n",
       "\\hline\n",
       "\t 0  &  3\\\\\n",
       "\t 0  &  5\\\\\n",
       "\t 0  & 10\\\\\n",
       "\t 0  & 15\\\\\n",
       "\t 0  & 20\\\\\n",
       "\t 0  & 50\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "decay | size | \n",
       "|---|---|---|---|---|---|\n",
       "| 0  |  3 | \n",
       "| 0  |  5 | \n",
       "| 0  | 10 | \n",
       "| 0  | 15 | \n",
       "| 0  | 20 | \n",
       "| 0  | 50 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  decay size\n",
       "1 0      3  \n",
       "2 0      5  \n",
       "3 0     10  \n",
       "4 0     15  \n",
       "5 0     20  \n",
       "6 0     50  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(caret)\n",
    "fitControl <- trainControl(## 10-fold CV\n",
    "                           method = \"cv\",\n",
    "                           number = 3)\n",
    "\n",
    "parameterGrid <-  expand.grid(decay=0,\n",
    "                              size=c(3,5,10,15,20,50))\n",
    "\n",
    "                        \n",
    "parameterGrid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neural Network \n",
       "\n",
       "2300 samples\n",
       "  57 predictor\n",
       "   2 classes: '0', '1' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (3 fold) \n",
       "Summary of sample sizes: 1534, 1533, 1533 \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  size  Accuracy   Kappa    \n",
       "   3    0.9182567  0.8298434\n",
       "   5    0.9113077  0.8120088\n",
       "  10    0.9156542  0.8231633\n",
       "  15    0.9052211  0.8027368\n",
       "  20    0.9078264  0.8068880\n",
       "  50    0.9108692  0.8124990\n",
       "\n",
       "Tuning parameter 'decay' was held constant at a value of 0\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final values used for the model were size = 3 and decay = 0."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(825)\n",
    "model_caret <- train(is_spam ~ ., data = train_data, \n",
    "                 method = \"nnet\", \n",
    "                 trControl = fitControl, \n",
    "                 verbose = FALSE,\n",
    "                 skip=FALSE,\n",
    "                 maxit=10000,\n",
    "                 trace=F,\n",
    "                 rang=0.2,\n",
    "                 MaxNWts=10000,\n",
    "                 ## Now specify the exact models \n",
    "                 ## to evaluate:\n",
    "                 tuneGrid = parameterGrid)\n",
    "model_caret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAM1BMVEUAAABNTU1oaGh8fHyM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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trellis.par.set(caretTheme())\n",
    "plot(model_caret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radial Basis Functions - RSNNS\n",
    "\n",
    "The following code allows to fit a radial basis function (RBF [Slides 62-67](https://uv.ulb.ac.be/pluginfile.php/1257539/mod_resource/content/3/algos.pdf)) model, using the R package RSNNS, setting the number of centers to 5 and the maximum number of iterations to 10000. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train <- as.numeric(levels(train_data[,target_variable]))[train_data[,target_variable]]\n",
    "Y_test <- as.numeric(levels(test_data[,target_variable]))[test_data[,target_variable]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_train <- prcomp(train_data[, -target_variable],center=TRUE,scale.=TRUE,retx=TRUE)\n",
    "pca_test <- prcomp(train_data[, -target_variable],center=TRUE,scale.=TRUE,retx=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbfn_model <- RSNNS::rbf(as.matrix(pca_train$x[,1:5]), \n",
    "                         as.matrix(Y_train), \n",
    "                         size=5,    # number of centers, ie, number of neurons in hidden layer\n",
    "                         maxit=10000,\n",
    "                         shufflePatterns=TRUE,\n",
    "                         linout=FALSE) # max number of iterations to learn \n",
    "\n",
    "Y_pred_rbfn <- predict(rbfn_model,pca_test$x[,1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nkAAFhAQoICRAASEBCggJUPAf2cEgdeIm/UEAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotIterativeError(rbfn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Y_test\n",
       "       0    1\n",
       "  0 1407  894"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix <- table(round(Y_pred_rbfn),Y_test)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"[INFO] - Misclassification Rate - RSNNS: 0.146458061712299\"\n"
     ]
    }
   ],
   "source": [
    "accuracy = (confusion_matrix[1,1]+confusion_matrix[2,2])/sum(confusion_matrix)\n",
    "misclassification_rate = 1 - accuracy\n",
    "print(paste(\"[INFO] - Misclassification Rate - RSNNS:\",misclassification_rate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Y_test\n",
      "       0    1\n",
      "  0 1359  901\n",
      "  1   16   25\n",
      "[1] \"[INFO] - Misclassification Rate - RSNNS: 0.398522381573229\"\n",
      "   Y_test\n",
      "       0    1\n",
      "  0 1373  917\n",
      "  1    2    9\n",
      "[1] \"[INFO] - Misclassification Rate - RSNNS: 0.399391568883094\"\n",
      "   Y_test\n",
      "       0    1\n",
      "  0 1346  895\n",
      "  1   29   31\n",
      "[1] \"[INFO] - Misclassification Rate - RSNNS: 0.401564537157758\"\n",
      "   Y_test\n",
      "       0    1\n",
      "  0 1358  898\n",
      "  1   17   28\n",
      "[1] \"[INFO] - Misclassification Rate - RSNNS: 0.397653194263364\"\n",
      "   Y_test\n",
      "       0    1\n",
      "  0 1310  828\n",
      "  1   65   98\n",
      "[1] \"[INFO] - Misclassification Rate - RSNNS: 0.388092133854846\"\n",
      "   Y_test\n",
      "       0    1\n",
      "  0 1355  890\n",
      "  1   20   36\n",
      "[1] \"[INFO] - Misclassification Rate - RSNNS: 0.395480225988701\"\n",
      "   Y_test\n",
      "      0   1\n",
      "  0 922 243\n",
      "  1 453 683\n",
      "[1] \"[INFO] - Misclassification Rate - RSNNS: 0.302477183833116\"\n",
      "   Y_test\n",
      "      0   1\n",
      "  0 972 256\n",
      "  1 403 670\n",
      "[1] \"[INFO] - Misclassification Rate - RSNNS: 0.286397218600608\"\n",
      "   Y_test\n",
      "      0   1\n",
      "  0 929 251\n",
      "  1 446 675\n",
      "[1] \"[INFO] - Misclassification Rate - RSNNS: 0.302911777488049\"\n"
     ]
    }
   ],
   "source": [
    "centers <- c(5,10,15,20,30,50,100,150,200)\n",
    "accuracy_vec <- numeric()\n",
    "\n",
    "for(center in centers){\n",
    "    rbfn_model <- RSNNS::rbf(as.matrix(train_data[,-target_variable]), \n",
    "                         as.matrix(Y_train), \n",
    "                         size=center,    # number of centers, ie, number of neurons in hidden layer\n",
    "                         maxit=1000) # max number of iterations to learn \n",
    "\n",
    "    Y_pred_rbfn <- predict(rbfn_model, test_data[,-target_variable])\n",
    "    confusion_matrix <- table(ifelse(round(Y_pred_rbfn) == 0,0,1),Y_test)\n",
    "    print(confusion_matrix)\n",
    "    accuracy <- (confusion_matrix[1,1]+confusion_matrix[2,2])/sum(confusion_matrix)\n",
    "    misclassification_rate = 1 - accuracy\n",
    "    print(paste(\"[INFO] - Misclassification Rate - RSNNS:\",misclassification_rate))\n",
    "    \n",
    "    accuracy_vec <- cbind(accuracy_vec,accuracy)\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
